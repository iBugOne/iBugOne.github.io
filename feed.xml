<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.3.2">Jekyll</generator><link href="https://ibug.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://ibug.io/" rel="alternate" type="text/html" /><updated>2023-10-29T19:21:13+00:00</updated><id>https://ibug.io/feed.xml</id><title type="html">iBug</title><subtitle>The little personal site for iBug</subtitle><author><name>iBug</name></author><entry><title type="html">Understanding ZFS block sizes</title><link href="https://ibug.io/blog/2023/10/zfs-block-size/" rel="alternate" type="text/html" title="Understanding ZFS block sizes" /><published>2023-10-30T00:00:00+00:00</published><updated>2023-10-30T02:58:51+00:00</updated><id>https://ibug.io/blog/2023/10/zfs-block-size</id><content type="html" xml:base="https://ibug.io/blog/2023/10/zfs-block-size/"><![CDATA[<p>ZFS is about the most complex filesystem for single-node storage servers. Coming with its sophistication is its equally confusing “block size”, which is normally self-evident on common filesystems like ext4 (or more primitively, FAT). The enigma continues as ZFS bundles more optimizations, either for performance or in the name of “intuition” (which I would hardly agree). So recently I read a lot of materials on this and try to make sense of it.</p>
			<p>We’ll begin with a slide from a ZFS talk from Lustre<sup id="fnref:dilger" role="doc-noteref"><a href="#fn:dilger" class="footnote" rel="footnote">1</a></sup> (page 5):</p>
			<figure class="">
				<img src="/image/zfs/zfs-io-stack.png" alt="ZFS I/O Stack" />
				<figcaption>
					Figure 1. ZFS I/O Stack
				</figcaption>
			</figure>
			<!-- This article will focus on the topmost layer (ZPL and DMU) and the lowermost layer (vdev and disk sectors). -->
			<h2 id="logical-blocks">Logical blocks</h2>
			<p>The first thing to understand is that there are at least two levels of “block” concepts in ZFS. There’s “logical blocks” on an upper layer (DMU), and “physical blocks” on a lower layer (vdev). The latter is easier to understand and it’s almost synonymous to “disk sectors”. It’s precisely the <code class="language-plaintext highlighter-rouge">ashift</code> parameter in <code class="language-plaintext highlighter-rouge">zpool create</code> command and usually matches the physical sector size of your disks (4 KiB for modern disks). Once set, <code class="language-plaintext highlighter-rouge">ashift</code> is immutable and can only be changed when recreating the entire vdev array (fortunately not the entire pool<sup id="fnref:zfs101" role="doc-noteref"><a href="#fn:zfs101" class="footnote" rel="footnote">2</a></sup>). The “logical block”, however, is slightly more complicated, and beyond the expressibility of a few words. In short, it’s the smallest <em>meaningful</em> unit of data that ZFS can operate on, including reading, writing, checksumming, compression and deduplication.</p>
			<h3 id="recordsize-and-volblocksize">“recordsize” and “volblocksize”</h3>
			<p>You’ve probably seen <code class="language-plaintext highlighter-rouge">recordsize</code> being talked about extensively in ZFS tuning guides<sup id="fnref:tuning" role="doc-noteref"><a href="#fn:tuning" class="footnote" rel="footnote">3</a></sup>, which is already a great source of confusion. The default <code class="language-plaintext highlighter-rouge">recordsize</code> is 128 KiB, which controls the <em>maximum</em> size of a logical block. The <em>actual</em> block size depends on the file you’re writing:</p>
			<ul>
				<li>If the file is smaller than or equal to <code class="language-plaintext highlighter-rouge">recordsize</code>, it’s stored as a single logical block of its size, rounded up to the nearest multiple of 512 bytes.</li>
				<li>If the file is larger than <code class="language-plaintext highlighter-rouge">recordsize</code>, it’s split into multiple logical blocks of <code class="language-plaintext highlighter-rouge">recordsize</code> each, with the last block being zero-padded to <code class="language-plaintext highlighter-rouge">recordsize</code>.</li>
			</ul>
			<p>As with other filesystems, if you change a small portion of a large file, only 128 KiB (or whatever your <code class="language-plaintext highlighter-rouge">recordsize</code> is) is rewritten, along with new metadata and checksums. Large <code class="language-plaintext highlighter-rouge">recordsize</code> bloats the read/write amplification for random I/O workloads, while small <code class="language-plaintext highlighter-rouge">recordsize</code> increases the fragmentation and metadata overhead for large files. Note that ZFS always validates checksums, so every read operation is done on an entire block, even if only a few bytes are requested. So it is important to align your <code class="language-plaintext highlighter-rouge">recordsize</code> with your workload, like using 16 KiB for (most) databases and 1 MiB for media files. The default 128 KiB is a good compromise for general-purpose workloads, and there certainly isn’t a one-size-fits-all solution. Also note that while <code class="language-plaintext highlighter-rouge">recordsize</code> can be changed on the fly, it only affects newly written data, and existing ones stay intact.</p>
			<p>For ZVOLs, as you’d imagine, the rule is much simpler: Every block of <code class="language-plaintext highlighter-rouge">volblocksize</code> is a logical block, and it’s aligned to its own size. Since ZFS 2.2, the default <code class="language-plaintext highlighter-rouge">volblocksize</code> is 16 KiB, providing a good balance between performance and compatibility.</p>
			<h3 id="compression">Compression</h3>
			<p>Compression is applied on a per-block basis, and compressed data is not shared between blocks. This is best shown with an example:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>zfs get compression tank/test
<span class="go">NAME       PROPERTY     VALUE  SOURCE
tank/test  compression  zstd   inherited from tank
</span><span class="gp">$</span><span class="w"> </span><span class="nb">head</span> <span class="nt">-c</span> 131072 /dev/urandom <span class="o">&gt;</span> 128k
<span class="gp">$</span><span class="w"> </span><span class="nb">cat </span>128k 128k 128k 128k 128k 128k 128k 128k <span class="o">&gt;</span> 1m
<span class="gp">$</span><span class="w"> </span><span class="nb">du</span> <span class="nt">-sh</span> 128k 1m
<span class="go">129K    128k
1.1M    1m
</span></code></pre>
				</div>
			</div>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span><span class="nb">head</span> <span class="nt">-c</span> 16384 /dev/urandom <span class="o">&gt;</span> 16k
<span class="gp">$</span><span class="w"> </span><span class="nb">cat </span>16k 16k 16k 16k 16k 16k 16k 16k <span class="o">&gt;</span> 128k1
<span class="gp">$</span><span class="w"> </span><span class="nb">cat </span>128k1 128k1 128k1 128k1 128k1 128k1 128k1 128k1 <span class="o">&gt;</span> 1m1
<span class="gp">$</span><span class="w"> </span><span class="nb">du</span> <span class="nt">-sh</span> 16k 128k1 1m1
<span class="go">17K     16k
21K     128k1
169K    1m1
</span></code></pre>
				</div>
			</div>
			<p>As you can see from <code class="language-plaintext highlighter-rouge">du</code>’s output above, despite containing 8 identical copies of the same 128 KiB random data, the 1 MiB file gains precisely nothing from compression, as each 128 KiB block is compressed individually. The other test of combining 8 copies of 16 KiB random data into one 128 KiB file shows positive results, as the 128 KiB file is only 21 KiB in size. Similarly, the 1 MiB file that contains 64 exact copies of the same 16 KiB chunk is exactly 8 times the size of that 128 KiB file, because the chunk data is not shared across 128 KiB boundaries.</p>
			<p>This brings up an interesting point: <strong>It’s beneficial to turn on compression even for filesystems with uncompressible data</strong><sup id="fnref:cks-1" role="doc-noteref"><a href="#fn:cks-1" class="footnote" rel="footnote">4</a></sup>. One direct impact is on the last block of a large file, where its zero-filled bytes up to <code class="language-plaintext highlighter-rouge">recordsize</code> compress very well. Using LZ4 or ZSTD, compression should have negligible impact on any reasonably modern CPU and reasonably sized disks.</p>
			<p>There are two more noteworthy points about compression, both from <a href="https://openzfs.github.io/openzfs-docs/man/master/7/zfsprops.7.html"><code class="language-plaintext highlighter-rouge">man zfsprops.7</code></a>:</p>
			<ol>
				<li>
					<blockquote>
						<p>When any setting except <strong>off</strong> is selected, compression will explicitly check for blocks consisting of only zeroes (the NUL byte). When a zero-filled block is detected, it is stored as a hole and not compressed using the indicated compression algorithm.</p>
					</blockquote>
					<p>Instead of compressing entire blocks of zeroes like the last block of a large file, ZFS will not store anything about these zero blocks. Technically, this is done by omitting the corresponding ranges from the file’s indirect blocks<sup id="fnref:cks-1:1" role="doc-noteref"><a href="#fn:cks-1" class="footnote" rel="footnote">4</a></sup>.</p>
					<p>Take this test for example: I created a file with 64 KiB of urandom, then 256 KiB of zeroes, then another 64 KiB of urandom. The file is 384 KiB in size, but only 128 KiB is actually stored on disk:</p>
					<div class="language-console highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zfs create pool0/srv/test
<span class="gp">#</span><span class="w"> </span><span class="nb">cat</span> &lt;<span class="o">(</span><span class="nb">head</span> <span class="nt">-c</span> 64K /dev/urandom<span class="o">)</span> &lt;<span class="o">(</span><span class="nb">head</span> <span class="nt">-c</span> 256K /dev/zero<span class="o">)</span> &lt;<span class="o">(</span><span class="nb">head</span> <span class="nt">-c</span> 64K /dev/urandom<span class="o">)</span> <span class="o">&gt;</span> /srv/test/test
<span class="gp">#</span><span class="w"> </span><span class="nb">du</span> <span class="nt">-sh</span> /srv/test/test
<span class="go">145K    /srv/test/test
</span></code></pre>
						</div>
    </div>
					<p>We can also examine the file’s indirect blocks with <code class="language-plaintext highlighter-rouge">zdb</code>:</p>
					<div class="language-console highlighter-rouge">
						<div class="highlight">
							<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span><span class="nb">ls</span> <span class="nt">-li</span> /srv/test/test
<span class="go">2 -rw-r--r-- 1 root root 393216 Oct 30 02:05 /srv/test/test
</span><span class="gp">#</span><span class="w"> </span>zdb <span class="nt">-ddddd</span> pool0/srv/test 2
<span class="go">[...]
Indirect blocks:
               0 L1  0:1791b7d3000:1000 20000L/1000P F=2 B=9769680/9769680 cksum=[...]
               0  L0 0:1791b7b1000:11000 20000L/11000P F=1 B=9769680/9769680 cksum=[...]
           40000  L0 0:1791b7c2000:11000 20000L/11000P F=1 B=9769680/9769680 cksum=[...]

                segment [0000000000000000, 0000000000020000) size  128K
                segment [0000000000040000, 0000000000060000) size  128K
</span></code></pre>
						</div>
    </div>
					<p>Here we can see only two L0 blocks allocated, each being 20000 (hex, dec = 131072) bytes logical and 11000 (hex, dec = 69632) bytes physical in size. The two L0 blocks match the two segments shown at the bottom, with the middle segment nowhere to be found.</p>
				</li>
				<li>
					<blockquote>
						<p>Any block being compressed must be no larger than 7/8 of its original size after compression, otherwise the compression will not be considered worthwhile and the block saved uncompressed. […] for example, 8 KiB blocks on disks with 4 KiB disk sectors must compress to 1/2 or less of their original size.</p>
					</blockquote>
					<p>This one should be self-explanatory.</p>
				</li>
			</ol>
			<h2 id="raidz">RAIDZ</h2>
			<p>Up until now we’ve only talked about logical blocks, which are all on the higher layers of the ZFS hierarchy. RAIDZ is where physical blocks (disk sectors) really come into play and adds another field of confusion.</p>
			<p>Unlike traditional RAID 5/6/7<sup class="no-select">(?)</sup> that combine disks into an array and presents a single volume for the filesystem, RAIDZ handles each <em>logical block</em> separately. I’ll cite this illustration from Delphix<sup id="fnref:delphix" role="doc-noteref"><a href="#fn:delphix" class="footnote" rel="footnote">5</a></sup> to explain:</p>
			<figure class="">
				<img src="/image/zfs/raidz-block-layout.png" alt="RAID-Z block layout" />
				<figcaption>
					Figure 2. RAID-Z block layout
				</figcaption>
			</figure>
			<p>This example shows a 5-wide RAID-Z1 setup.</p>
			<ul>
				<li>A single-sector block takes another sector for parity, like the dark red block on row 3.</li>
				<li>
					<p>Multi-sector blocks are striped across disks, with parity sectors inserted every 4 sectors, matching the data-to-parity ratio of the vdev array.</p>
					<ul>
						<li>You may have noticed that parity sectors for the same block are always stored on the same disk that resembles RAID-4 instead of RAID-5. Keep in mind that ZFS reads, writes and verifies entire blocks, so interleaving parity sectors across disks will not provide any benefit, while keeping “stripes” on the same disk simplifies the logic for validation and reconstruction.</li>
					</ul>
				</li>
				<li>In order to avoid unusable fragments, ZFS requires each allocated block to be padded to a multiple of (<em>p+1</em>) sectors, where <em>p</em> is the number of parity disks. For example, RAID-Z1 requires each block to be padded to a multiple of 2 sectors, and RAID-Z2 requires each block to be padded to a multiple of 3 sectors. This can be seen on rows 7 to 9, where the X sectors are reserved for parity padding.</li>
			</ul>
			<p>This design allows RAID to play well with ZFS’s log-structured design and avoids the need for read-modify-write cycles. Consequently, the RAID overhead is now dependent on your data and is no longer an intrinsic property of the RAID level and array width. The same Delphix article shares a nice spreadsheet<sup id="fnref:delphix-spreadsheet" role="doc-noteref"><a href="#fn:delphix-spreadsheet" class="footnote" rel="footnote">6</a></sup> that calculates RAID overhead for you:</p>
			<p><a href="https://docs.google.com/a/delphix.com/spreadsheets/d/1tf4qx1aMJp8Lo_R6gpT689wTjHv6CGVElrPqTA0w_ZY/"><img src="/image/zfs/raidz1-parity-overhead.png" alt="Size of parity overhead for RAID-Z1" /></a></p>
			<h3 id="raidz-accounting">Accounting</h3>
			<p>Accounting the storage space for a RAIDZ array is as problematic as it seems: There’s no way to calculate the available space in advance without knowledge on the block size pattern.</p>
			<p>ZFS works around this by showing an estimate, assuming all data were stored as 128 KiB blocks<sup id="fnref:zfs-4599" role="doc-noteref"><a href="#fn:zfs-4599" class="footnote" rel="footnote">7</a></sup>. On my test setup with five 16 GiB disks in RAID-Z1 and <code class="language-plaintext highlighter-rouge">ashift=12</code>, the available space shows as 61.5G, while <code class="language-plaintext highlighter-rouge">zpool</code> shows the raw size as 79.5G:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zpool create <span class="nt">-o</span> <span class="nv">ashift</span><span class="o">=</span>12 <span class="nb">test </span>raidz1 nvme3n1p<span class="o">{</span>1,2,3,4,5<span class="o">}</span>
<span class="gp">#</span><span class="w"> </span>zfs list <span class="nb">test</span>
<span class="go">NAME   USED  AVAIL     REFER  MOUNTPOINT
test   614K  61.5G      153K  /test
</span><span class="gp">#</span><span class="w"> </span>zpool list <span class="nb">test</span>
<span class="go">NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
test  79.5G   768K  79.5G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre>
				</div>
			</div>
			<p>When I increase <code class="language-plaintext highlighter-rouge">ashift</code> to 15 (32 KiB sectors), the available space drops quite a bit, even if <code class="language-plaintext highlighter-rouge">zpool</code> shows the same raw size:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zpool create <span class="nt">-o</span> <span class="nv">ashift</span><span class="o">=</span>15 <span class="nb">test </span>raidz1 nvme3n1p<span class="o">{</span>1,2,3,4,5<span class="o">}</span>
<span class="gp">#</span><span class="w"> </span>zfs list <span class="nb">test</span>
<span class="go">NAME   USED  AVAIL     REFER  MOUNTPOINT
test  4.00M  51.3G     1023K  /test
</span><span class="gp">#</span><span class="w"> </span>zpool list <span class="nb">test</span>
<span class="go">NAME   SIZE  ALLOC   FREE  CKPOINT  EXPANDSZ   FRAG    CAP  DEDUP    HEALTH  ALTROOT
test  79.5G  7.31M  79.5G        -         -     0%     0%  1.00x    ONLINE  -
</span></code></pre>
				</div>
			</div>
			<p>In both cases, calculating the “raw” disk space from the available space gives roughly congruent results:</p>
			<ul>
				<li>61.5 GiB × (1 + 25%) = 76.9 GiB</li>
				<li>51.3 GiB × (1 + 50%) = 76.9 GiB</li>
			</ul>
			<p>The default <code class="language-plaintext highlighter-rouge">refreservation</code> for non-sparse ZVOLs exhibits a similar behavior:</p>
			<div class="language-console highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="gp">#</span><span class="w"> </span>zfs create <span class="nt">-V</span> 4G <span class="nt">-o</span> <span class="nv">volblocksize</span><span class="o">=</span>8K <span class="nb">test</span>/v8k
<span class="gp">#</span><span class="w"> </span>zfs create <span class="nt">-V</span> 4G <span class="nt">-o</span> <span class="nv">volblocksize</span><span class="o">=</span>16K <span class="nb">test</span>/v16k
<span class="gp">#</span><span class="w"> </span>zfs get refreservation <span class="nb">test</span>/v8k <span class="nb">test</span>/v16k
<span class="go">NAME       PROPERTY        VALUE      SOURCE
test/v16k  refreservation  4.86G      local
test/v8k   refreservation  6.53G      local
</span></code></pre>
				</div>
			</div>
			<p>Interestingly, neither of the <code class="language-plaintext highlighter-rouge">refreservation</code> sizes matches the RAID overhead as calculated in the Delphix spreadsheet<sup id="fnref:delphix-spreadsheet:1" role="doc-noteref"><a href="#fn:delphix-spreadsheet" class="footnote" rel="footnote">6</a></sup>, as you would expect some 6.0 GiB for the 16k-volblocksized ZVOL and some 8.0 GiB for the 8k-volblocksized one. <strong>Let’s just don’t forget that the whole accounting system assumed 128 KiB blocks and scaled by that<sup id="fnref:acct-128k" role="doc-noteref"><a href="#fn:acct-128k" class="footnote" rel="footnote">8</a></sup>.</strong> So the actual meaning of 4.86G and 6.53G would be “the <em>equivalent</em> space if volblocksize had been 128 KiB”. If we multiply both values by 1.25 (overhead for 128 KiB blocks and 5-wide RAIDZ), we get 6.08 GiB and 8.16 GiB of raw disk spaces respectively, both of which match more closely the expected values. The final minor difference is due to the different amount of metadata required for different number of blocks.</p>
			<h2 id="thoughts">Thoughts</h2>
			<p>I never imagined I would delve this deep into ZFS when I first stumbled upon the question. There are lots of good write-ups on individual components of ZFS all around the web, and <a href="https://utcc.utoronto.ca/~cks/space/blog/">Chris Siebenmann’s blog</a> in particular. But few combine all the pieces together and paint the whole picture, so I had to spend some time synthesizing them by myself. As you’ve seen in the Luster slide, ZFS is so complex a beast that it’s hard to digest in its entirety. So for now I have no idea how much effort I would put into learning it, nor any future blogs I would write. But anyways, that’s one large mystery solved, for myself and my readers (you), and time to call it a day.</p>
			<h2 id="references">References</h2>
			<div class="footnotes" role="doc-endnotes">
				<ol>
					<li id="fn:dilger" role="doc-endnote">
						<p>Andreas Dilger (2010) <a href="https://wiki.lustre.org/images/4/49/Beijing-2010.2-ZFS_overview_3.1_Dilger.pdf">ZFS Features &amp; Concepts TOI</a> <a href="#fnref:dilger" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
					</li>
					<li id="fn:zfs101" role="doc-endnote">
						<p>Jim Salter (2020) <a href="https://arstechnica.com/information-technology/2020/05/zfs-101-understanding-zfs-storage-and-performance/">ZFS 101 – Understanding ZFS storage and performance</a> <a href="#fnref:zfs101" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
					</li>
					<li id="fn:tuning" role="doc-endnote">
						<p>OpenZFS <a href="https://openzfs.github.io/openzfs-docs/Performance%20and%20Tuning/Workload%20Tuning.html">Workload Tuning</a> <a href="#fnref:tuning" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
					</li>
					<li id="fn:cks-1" role="doc-endnote">
						<p>Chris Siebenmann (2017) <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFilePartialAndHoleStorage">ZFS’s recordsize, holes in files, and partial blocks</a> <a href="#fnref:cks-1" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:cks-1:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
					</li>
					<li id="fn:delphix" role="doc-endnote">
						<p>Matthew Ahrens (2014) <a href="https://www.delphix.com/blog/zfs-raidz-stripe-width-or-how-i-learned-stop-worrying-and-love-raidz">How I Learned to Stop Worrying and Love RAIDZ</a> <a href="#fnref:delphix" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
					</li>
					<li id="fn:delphix-spreadsheet" role="doc-endnote">
						<p><a href="https://docs.google.com/a/delphix.com/spreadsheets/d/1tf4qx1aMJp8Lo_R6gpT689wTjHv6CGVElrPqTA0w_ZY/">RAID-Z parity cost</a> (Google Sheets) <a href="#fnref:delphix-spreadsheet" class="reversefootnote" role="doc-backlink">&#8617;</a> <a href="#fnref:delphix-spreadsheet:1" class="reversefootnote" role="doc-backlink">&#8617;<sup>2</sup></a></p>
					</li>
					<li id="fn:zfs-4599" role="doc-endnote">
						<p>openzfs/zfs#4599 (2016) <a href="https://github.com/openzfs/zfs/issues/4599">disk usage wrong when using larger recordsize, raidz and ashift=12</a> <a href="#fnref:zfs-4599" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
					</li>
					<li id="fn:acct-128k" role="doc-endnote">
						<p>Mike Gerdts (2019) <a href="https://github.com/illumos/illumos-gate/blob/b73ccab03ec36581b1ae5945ef1fee1d06c79ccf/usr/src/lib/libzfs/common/libzfs_dataset.c#L5118">(Code comment in <code class="language-plaintext highlighter-rouge">libzfs_dataset.c</code>)</a> <a href="#fnref:acct-128k" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
					</li>
				</ol>
			</div>
			]]></content><author><name>iBug</name></author><category term="linux" /><category term="zfs" /><summary type="html"><![CDATA[ZFS is about the most complex filesystem for single-node storage servers. Coming with its sophistication is its equally confusing “block size”, which is normally self-evident on common filesystems like ext4 (or more primitively, FAT). The enigma continues as ZFS bundles more optimizations, either for performance or in the name of “intuition” (which I would hardly agree). So recently I read a lot of materials on this and try to make sense of it.]]></summary></entry><entry><title type="html">Debugging Proxmox VE Firewall Dropping TCP Reset Packets</title><link href="https://ibug.io/blog/2023/10/pve-firewall-drops-tcp-reset/" rel="alternate" type="text/html" title="Debugging Proxmox VE Firewall Dropping TCP Reset Packets" /><published>2023-10-06T00:00:00+00:00</published><updated>2023-10-06T13:37:51+00:00</updated><id>https://ibug.io/blog/2023/10/pve-firewall-drops-tcp-reset</id><content type="html" xml:base="https://ibug.io/blog/2023/10/pve-firewall-drops-tcp-reset/"><![CDATA[<p>A few days back when I was setting up a new VM to host some extra websites, I noticed an unexpected Nginx error page. As I don’t administer the new websites, I just added reverse proxy rules on the gateway Nginx server, and deferred the actual configuration to whoever is in charge of them.</p>
		<p>When I reviewed my edited Nginx configuration and tried visiting the new website, I received a 504 Gateway Timeout error after <code class="language-plaintext highlighter-rouge">curl</code> hung for a minute. Knowing that the web server had yet to be set up, I was expecting a 502 Bad Gateway error. I quickly recalled the conditions for Nginx to return these specific errors: 502 if the upstream server is immediately known down, and 504 if the upstream server is up but not responding.</p>
		<p>Since the actual web application hadn’t been set up yet, the new VM should have nothing listening on the configured ports. Consequently, the kernel should immediately respond with a TCP Reset for any incoming connections. To verify this, I ran <code class="language-plaintext highlighter-rouge">tcpdump</code> on both sides to check if the TCP reset packets actually came out. To my surprise, the packets were indeed sent out from the new VM, but the gateway server received nothing. So there was certainly something wrong with the firewall. I took a glance at the output of <code class="language-plaintext highlighter-rouge">pve-firewall compile</code>. They were very structured and adequately easy to understand, but I couldn’t immediately identify anything wrong. Things were apparently more complicated than I had previously anticipated.</p>
		<h2 id="searching">Searching for information</h2>
		<p>As usual, the first thing to try is Googling. Searching for <code class="language-plaintext highlighter-rouge">pve firewall tcp reset</code> brought <a href="https://forum.proxmox.com/threads/tcp-rst-packets-dropped-by-pve-firewall.56300/">this post on Proxmox Forum</a> as the first result. Their symptoms were precisely the same as mine:</p>
		<blockquote>
			<ul>
				<li>Assume we have a service running on TCP port 12354</li>
				<li>Clients can communicate with it while running</li>
				<li>While service is down, clients recieved “Connection timed out” (no answer) even if OS send TCP RST packets:</li>
			</ul>
			<p>[…]</p>
			<p>However, these RST packets are dropped somewhere in PVE firewall.<br />
				On the VM options :</p>
			<ul>
				<li>Firewall &gt; Options &gt; Firewall = No, Has no effect</li>
				<li>Firewall &gt; Options &gt; * Policy = ACCEPT, Has no effect (even with NO rule in active for this VM)</li>
				<li>Hardware &gt; Network Device &gt; <code class="language-plaintext highlighter-rouge">firewall=0</code>, allows packets RST to pass!</li>
			</ul>
		</blockquote>
		<p>I gave the last suggestion a try, and it worked! I could now see connections immediately reset on the gateway server, and Nginx started producing 502 errors. But I was still confused why this happened in the first place. The first thread contained nothing else useful, so I continued scanning through other search results and noticed <a href="https://forum.proxmox.com/threads/turning-on-the-pve-firewall-stops-vm-lxc-connectivity.55634/#post-261316">another post</a> about another seemingly unrelated problem, with a plausible solution:</p>
		<blockquote>
			<p>[…], and the fix was just to add the <code class="language-plaintext highlighter-rouge">nf_conntrack_allow_invalid: 1</code> in the <code class="language-plaintext highlighter-rouge">host.fw</code> for each node - I didn’t have to do anything other than that.</p>
		</blockquote>
		<p>That seemed understandable to me, so I gave it a try as well, and to my pleasure, it also worked.</p>
		<p>Regrettably, useful information ceased to exist online beyond this, and it was far from painting the whole picture. So anything further would have to be uncovered on my own.</p>
		<h2 id="reviewing">Reviewing information</h2>
		<p>I reviewed the two helpful workarounds and made myself abundantly clear about their effects:</p>
		<ul>
			<li>
				<p>Disabling the firewall on the virtual network device stops PVE from bridging the interface an extra time, as shown in the following diagram:</p>
				<p><img src="/image/pve-firewall/pve-fwbr.png" alt="PVE Firewall Diagram" /></p>
			</li>
			<li>
				<p>Adding <code class="language-plaintext highlighter-rouge">nf_conntrack_allow_invalid: 1</code> removes one single iptables rule:</p>
				<div class="language-shell highlighter-rouge">
					<div class="highlight">
						<pre class="highlight"><code><span class="nt">-A</span> PVEFW-FORWARD <span class="nt">-m</span> conntrack <span class="nt">--ctstate</span> INVALID <span class="nt">-j</span> DROP
</code></pre>
					</div>
    </div>
			</li>
		</ul>
		<p>I couldn’t figure out how the first difference was relevant, but the second one provided an important clue: The firewall was dropping TCP Reset packets because conntrack considered them invalid.</p>
		<p>Conntrack (<strong>conn</strong>ection <strong>track</strong>ing) is a Linux kernel subsystem that tracks network connections and aids in stateful packet inspection and network address translation. The first packet of a connection is considered “NEW”, and subsequent packets from the same connection are considered “ESTABLISHED”, including the TCP Reset packet when it’s first seen, which causes conntrack to delete the connection entry.</p>
		<p>There was still yet anything obvious, so time to start debugging.</p>
		<h2 id="tcpdump">Inspecting packet captures</h2>
		<p>I ran <code class="language-plaintext highlighter-rouge">tcpdump -ni any host 172.31.0.2 and host 172.31.1.11 and tcp</code> on the PVE host to capture packets between the two VMs. This is what I got (output trimmed):</p>
		<div class="language-text highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>tcpdump: data link type LINUX_SLL2
tcpdump: verbose output suppressed, use -v[v]... for full protocol decode
listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
16:33:11.911184 veth101i1 P   IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911202 fwln101i1 Out IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911203 fwpr101p1 P   IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911206 fwpr811p0 Out IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911207 fwln811i0 P   IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911213 tap811i0  Out IP 172.31.0.2.50198 &gt; 172.31.1.11.80: Flags [S], seq 3404503761, win 64240
16:33:11.911262 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.50198: Flags [R.], seq 0, ack 3404503762, win 0, length 0
16:33:11.911267 fwln811i0 Out IP 172.31.1.11.80 &gt; 172.31.0.2.50198: Flags [R.], seq 0, ack 1, win 0, length 0
16:33:11.911269 fwpr811p0 P   IP 172.31.1.11.80 &gt; 172.31.0.2.50198: Flags [R.], seq 0, ack 1, win 0, length 0
^C
9 packets captured
178 packets received by filter
0 packets dropped by kernel
</code></pre>
			</div>
		</div>
		<p><img src="/image/pve-firewall/fw-diagram-1.png" alt="Diagram" /></p>
		<p>The first thing to notice is the ACK number. After coming from <code class="language-plaintext highlighter-rouge">tap811i0</code>, it suddenly became 1 with no apparent reason. I struggled on this for a good while and temporarily put it aside.</p>
		<p>Adding <code class="language-plaintext highlighter-rouge">nf_conntrack_allow_invalid: 1</code> to the firewall options and capturing packets again, I got the following:</p>
		<div class="language-text highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
16:46:15.243002 veth101i1 P   IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243015 fwln101i1 Out IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243016 fwpr101p1 P   IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243020 fwpr811p0 Out IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243021 fwln811i0 P   IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243027 tap811i0  Out IP 172.31.0.2.58784 &gt; 172.31.1.11.80: Flags [S], seq 301948896, win 64240
16:46:15.243076 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 301948897, win 0, length 0
16:46:15.243081 fwln811i0 Out IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243083 fwpr811p0 P   IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243086 fwpr101p1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243087 fwln101i1 P   IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
16:46:15.243090 veth101i1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.58784: Flags [R.], seq 0, ack 1, win 0, length 0
^C
</code></pre>
			</div>
		</div>
		<p><img src="/image/pve-firewall/fw-diagram-2.png" alt="Diagram" /></p>
		<p>This time while the ACK number was still wrong, the RST packet somehow got through. Ignoring the ACK numbers for now, the output suggested that the RST packet was dropped between <code class="language-plaintext highlighter-rouge">fwpr811p0 P</code> and <code class="language-plaintext highlighter-rouge">fwln811i0 Out</code>. That was the main bridge <code class="language-plaintext highlighter-rouge">vmbr0</code>. All right then, that was where the <code class="language-plaintext highlighter-rouge">PVEFW-FORWARD</code> chain kicked in, so at this point the RST packet was <code class="language-plaintext highlighter-rouge">--ctstate INVALID</code>. Everything was logical so far.</p>
		<p>So how about disabling firewall for the interface on VM 811?</p>
		<div class="language-text highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
17:19:01.812030 veth101i1 P   IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812045 fwln101i1 Out IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812046 fwpr101p1 P   IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812051 tap811i0  Out IP 172.31.0.2.39734 &gt; 172.31.1.11.80: Flags [S], seq 1128018611, win 64240
17:19:01.812178 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1128018612, win 0, length 0
17:19:01.812183 fwpr101p1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1, win 0, length 0
17:19:01.812185 fwln101i1 P   IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1, win 0, length 0
17:19:01.812190 veth101i1 Out IP 172.31.1.11.80 &gt; 172.31.0.2.39734: Flags [R.], seq 0, ack 1, win 0, length 0
^C
</code></pre>
			</div>
		</div>
		<p><img src="/image/pve-firewall/fw-diagram-3.png" alt="Diagram" /></p>
		<p>This time <code class="language-plaintext highlighter-rouge">fwbr811i0</code> was missing, and the RST packet didn’t get dropped at <code class="language-plaintext highlighter-rouge">vmbr0</code>. I was left totally confused.</p>
		<p>I decided to sort out the ACK number issue, but ended up asking my friends for help. It turned out this was well documented in <code class="language-plaintext highlighter-rouge">tcpdump(8)</code>:</p>
		<blockquote>
			<p><code class="language-plaintext highlighter-rouge">-S</code><br />
				<code class="language-plaintext highlighter-rouge">--absolute-tcp-sequence-numbers</code><br />
				Print absolute, rather than relative, TCP sequence numbers.</p>
		</blockquote>
		<p>This certainly came out unexpected, but at least I was assured there was nothing wrong with the ACK numbers.</p>
		<p>Up to now, that’s one more step forward, and a small conclusion:</p>
		<ul>
			<li>At the point the RST packet reached <code class="language-plaintext highlighter-rouge">vmbr0</code>, it was already <code class="language-plaintext highlighter-rouge">--ctstate INVALID</code>.</li>
		</ul>
		<p>But how? As far as I knew, when the RST packet came out, it should still be considered part of the connection, and thus should be <code class="language-plaintext highlighter-rouge">--ctstate ESTABLISHED</code>. I was still missing something.</p>
		<p>Time to investigate conntrack.</p>
		<h2 id="conntrack">Inspecting conntrack</h2>
		<p><code class="language-plaintext highlighter-rouge">conntrack</code> is the tool to inspect and modify conntrack entries. I ran <code class="language-plaintext highlighter-rouge">conntrack -L</code> to list all entries, only to realize it’s inefficient. So instead, I ran <code class="language-plaintext highlighter-rouge">conntrack -E</code> to watch for “events” in real time, so that I could compare the output with <code class="language-plaintext highlighter-rouge">tcpdump</code>. Except that the entire connection concluded so quickly that I couldn’t identify anything.</p>
		<p>I had to add artificial delays to the packets to clearly separate each hop that the RST packet goes through:</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>tc qdisc add dev tap811i0 root netem delay 200ms
tc qdisc add dev fwln811i0 root netem delay 200ms
</code></pre>
			</div>
		</div>
		<p>I also tuned the output on both sides to show the timestamp in a consistent format. For conntrack, <code class="language-plaintext highlighter-rouge">-o timestamp</code> produced Unix timestamps (which is the only supported format), so for <code class="language-plaintext highlighter-rouge">tcpdump</code> I also resorted to <code class="language-plaintext highlighter-rouge">-tt</code> to show Unix timestamps as well.</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>conntrack <span class="nt">-E</span> <span class="nt">-o</span> timestamp <span class="nt">-s</span> 172.31.0.2 <span class="nt">-d</span> 172.31.1.11
tcpdump <span class="nt">-ttSni</span> any host 172.31.0.2 and host 172.31.1.11 and tcp
</code></pre>
			</div>
		</div>
		<p>Now I could watch the outputs on two separate tmux panes. The problem immediately emerged (blank lines added for readability):</p>
		<div class="language-text highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>listening on any, link-type LINUX_SLL2 (Linux cooked v2), snapshot length 262144 bytes
1696412047.886575 veth101i1 P   IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886592 fwln101i1 Out IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886594 fwpr101p1 P   IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886599 fwpr811p0 Out IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412047.886600 fwln811i0 P   IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]

1696412048.086620 tap811i0  Out IP 172.31.0.2.47066 &gt; 172.31.1.11.80: Flags [S]
1696412048.086841 tap811i0  P   IP 172.31.1.11.80 &gt; 172.31.0.2.47066: Flags [R.]

1696412048.286919 fwln811i0 Out IP 172.31.1.11.80 &gt; 172.31.0.2.47066: Flags [R.]
1696412048.286930 fwpr811p0 P   IP 172.31.1.11.80 &gt; 172.31.0.2.47066: Flags [R.]
^C
</code></pre>
			</div>
		</div>
		<div class="language-text highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>[1696412047.886657]         [NEW] tcp      6 120 SYN_SENT src=172.31.0.2 dst=172.31.1.11 sport=47066 dport=80 [UNREPLIED] src=172.31.1.11 dst=172.31.0.2 sport=80 dport=47066
[1696412048.086899]     [DESTROY] tcp      6 119 CLOSE src=172.31.0.2 dst=172.31.1.11 sport=47066 dport=80 [UNREPLIED] src=172.31.1.11 dst=172.31.0.2 sport=80 dport=47066
</code></pre>
			</div>
		</div>
		<p>The artificial delays and the timestamps were absolutely useful: It was clear that the corresponding conntrack connection was destroyed as soon as the RST packet passed through <code class="language-plaintext highlighter-rouge">fwbr811i0</code>, before it came out via <code class="language-plaintext highlighter-rouge">fwln811i0</code>. When it reached <code class="language-plaintext highlighter-rouge">vmbr0</code>, the connection was already gone, and the RST packet was considered invalid.</p>
		<p><img src="/image/pve-firewall/fw-diagram-4.png" alt="Diagram" /></p>
		<p>It also became explainable how <code class="language-plaintext highlighter-rouge">firewall=0</code> on the virtual network device remedied the issue: It removed an extra bridge <code class="language-plaintext highlighter-rouge">fwbr811i0</code>, so the connection stayed alive when the RST packet reached <code class="language-plaintext highlighter-rouge">vmbr0</code>, at which point a previous rule for <code class="language-plaintext highlighter-rouge">--ctstate ESTABLISHED</code> gave an <code class="language-plaintext highlighter-rouge">ACCEPT</code> verdict. While it was still <code class="language-plaintext highlighter-rouge">INVALID</code> when passing through <code class="language-plaintext highlighter-rouge">fwbr101i1</code>, there was no rule concerning <code class="language-plaintext highlighter-rouge">--ctstate</code> at play, so it slipped through this stage with no problem.</p>
		<p>After double-checking the intention of the extra <code class="language-plaintext highlighter-rouge">fwbr*</code> bridge, I drew the conclusion that <strong>this must be a bug with PVE Firewall</strong>. I reported it on the Proxmox VE bug tracker as <a href="https://bugzilla.proxmox.com/show_bug.cgi?id=4983">#4983</a>, and soon received a reply:</p>
		<blockquote>
			<p>Thank you for the detailed write-up!</p>
			<p>This is a known limitation for our kind of firewall setup, since the conntrack is shared between all interfaces on the host.</p>
			<p>[…]</p>
			<p>If you know of any other way to avoid this happening, other than using conntrack zones, I’d be happy to take a look.</p>
		</blockquote>
		<p>So they admitted that this was a limitation but without a satisfactory solution. Guess I’m still on my own, though.</p>
		<h2 id="solution">Finding the solution</h2>
		<p>The actual problem is, when passing through <code class="language-plaintext highlighter-rouge">fwbr811i0</code>, the RST packet isn’t supposed to be processed by conntrack by then. There is no <code class="language-plaintext highlighter-rouge">sysctl</code> option to disable conntrack on a specific interface (or even just all bridges altogether), but at the right time the rarely-used <code class="language-plaintext highlighter-rouge">raw</code> table came to my mind. It didn’t take long to work this out:</p>
		<div class="language-shell highlighter-rouge">
			<div class="highlight">
				<pre class="highlight"><code>iptables <span class="nt">-t</span> raw <span class="nt">-A</span> PREROUTING <span class="nt">-i</span> fwbr+ <span class="nt">-j</span> CT <span class="nt">--notrack</span>
</code></pre>
			</div>
		</div>
		<p>After verifying this is the intended solution, I added it as a reply to the bug report. At the time of writing this blog post, the bug report is still open, but I’m sure it’s to be resolved soon.</p>
		<h2 id="conclusion">Conclusion</h2>
		<p>Debugging Linux networking has always been a pain for its lack of proper tools and its complexity. Most of the times even reading and understanding packet captures requires immense knowledge of the protocols and all the involved components, as well as scrutinizing every single detail available. Sometimes it’s even necessary to think outside the box but fortunately not today.</p>
		<p>Also worth mentioning is that it’s easy to suspect the fault of another piece of software, but detailed investigation is always necessary to actually lay the blame.</p>
		<p>Just as a late reminder, useful bug reports always require detailed information and solid evidence. Glad I was able to have them at hand this time.</p>
		]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><category term="proxmox-ve" /><summary type="html"><![CDATA[A few days back when I was setting up a new VM to host some extra websites, I noticed an unexpected Nginx error page. As I don’t administer the new websites, I just added reverse proxy rules on the gateway Nginx server, and deferred the actual configuration to whoever is in charge of them.]]></summary></entry><entry><title type="html">Running a dual-protocol OpenVPN/WireGuard VPN server on one port</title><link href="https://ibug.io/blog/2023/09/dual-protocol-vpn-port/" rel="alternate" type="text/html" title="Running a dual-protocol OpenVPN/WireGuard VPN server on one port" /><published>2023-09-26T00:00:00+00:00</published><updated>2023-09-26T14:26:49+00:00</updated><id>https://ibug.io/blog/2023/09/dual-protocol-vpn-port</id><content type="html" xml:base="https://ibug.io/blog/2023/09/dual-protocol-vpn-port/"><![CDATA[<p>Public Wi-Fi and some campus network typically block traffic from unauthenticated clients, but more often allow traffic targeting UDP port 53 to pass through, which is normally used for DNS queries. This feature can be exploited to bypass authentication by connecting to a VPN server that’s also running on UDP 53.</p>
	<p>In previous times, OpenVPN was the general preference for personal VPN services. Since the emergence of WireGuard, however, popularity has shifted significantly for its simplicity and performance. A challenge presents itself as there’s only one UDP port numbered 53, making it seemingly impossible to run both OpenVPN and WireGuard on the same port.</p>
	<p>There solution hinges itself on a little bit of insights.</p>
	<h2 id="inspiration">Inspiration</h2>
	<p>In a similar situation, many local proxy software like Shadowsocks and V2ray support a feature called “mixed mode”, which accepts both HTTP and SOCKS5 connections on the same TCP port. This also seems impossible at first glance, but with a bit of knowledge in both protocols, it’s actually easy to pull it off.</p>
	<ul>
		<li>An HTTP proxy request, just like other HTTP requests, begins with an HTTP verb. In proxy requests, it’s either <code class="language-plaintext highlighter-rouge">GET</code> or <code class="language-plaintext highlighter-rouge">CONNECT</code>,</li>
		<li>A SOCKS proxy request begins with a 1-byte header containing its version, which is <code class="language-plaintext highlighter-rouge">0x04</code> for SOCKS4 or <code class="language-plaintext highlighter-rouge">0x05</code> for SOCKS5.</li>
	</ul>
	<p>Now there’s a clear line between the two protocols, and we can identify them by looking at the first byte of the request. This is how most proxy implementations work, like <a href="https://github.com/3proxy/3proxy/commit/fb56b7d307a7bce1f2109c73864bad7c71716f3b#diff-e268b23274bc9df1b2c0957dfa85d684519282ed611f6135e795205e53fb6e3b">3proxy</a> and <a href="https://github.com/nadoo/glider/blob/4f12a4f3082940d8a4c56ba4f06f02a72d90d5d6/proxy/mixed/mixed.go#L84">glider</a>.</p>
	<p>So the question is, is there a similar trait between OpenVPN and WireGuard? The answer is, as you would expect, yes.</p>
	<h2 id="protocols">Protocols</h2>
	<p>WireGuard runs over UDP and defines 4 packet types: 3 for handshake and 1 for data. All 4 packet types share the same 4-byte <a href="https://github.com/WireGuard/wireguard-linux/blob/fa41884c1c6deb6774135390e5813a97184903e0/drivers/net/wireguard/messages.h#L65">header</a>:</p>
	<div class="language-rust highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">struct</span> <span class="n">message_header</span> <span class="p">{</span>
    <span class="nb">u8</span> <span class="k">type</span><span class="p">;</span>
    <span class="nb">u8</span> <span class="n">reserved_zero</span><span class="p">[</span><span class="mi">3</span><span class="p">];</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>Similarly, all OpenVPN packet types share the same 1-byte <a href="https://build.openvpn.net/doxygen/network_protocol.html#network_protocol_external_types">header</a>:</p>
	<div class="language-c highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">struct</span> <span class="n">header_byte</span> <span class="p">{</span>
    <span class="kt">uint8_t</span> <span class="n">opcpde</span> <span class="o">:</span> <span class="mi">5</span><span class="p">;</span>
    <span class="kt">uint8_t</span> <span class="n">key_id</span> <span class="o">:</span> <span class="mi">3</span><span class="p">;</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>It’s worth noting that 0 is not a defined opcode, so the smallest valid value for this byte is 8, as <code class="language-plaintext highlighter-rouge">key_id</code> can be anything from 0 to 7.</p>
	<h2 id="implementation">Implementation</h2>
	<p>Now that we have the packet format for both protocols understood, we can implement a classifier that filters traffic in one protocol from the other.</p>
	<p>Considering that the WireGuard packet format is much simpler than that of OpenVPN, I choose to identify WireGuard. With kernel firewall <code class="language-plaintext highlighter-rouge">iptables</code>, options are abundant, though I find <code class="language-plaintext highlighter-rouge">u32</code> the easiest:</p>
	<div class="language-sh highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">*</span>nat
:iBugVPN - <span class="o">[</span>0:0]
<span class="nt">-A</span> PREROUTING <span class="nt">-m</span> addrtype <span class="nt">--dst-type</span> LOCAL <span class="nt">-p</span> udp <span class="nt">--dport</span> 53 <span class="nt">-j</span> iBugVPN
<span class="nt">-A</span> iBugVPN <span class="nt">-m</span> u32 <span class="nt">--u32</span> <span class="s2">"25 &amp; 0xFF = 1:4 &amp;&amp; 28 &amp; 0xFFFFFF = 0"</span> <span class="nt">-j</span> REDIRECT <span class="nt">--to-port</span> 51820
<span class="nt">-A</span> iBugVPN <span class="nt">-j</span> REDIRECT <span class="nt">--to-port</span> 1194
COMMIT
</code></pre>
		</div>
	</div>
	<p>With both OpenVPN and WireGuard running on their standard ports, this will redirect each protocol to its respective service port. While these rules only operate on the initial packet, Linux conntrack will handle the rest of the connection.</p>
	<p>The <code class="language-plaintext highlighter-rouge">u32</code> match is explained:</p>
	<ul>
		<li>Basic syntax: <code class="language-plaintext highlighter-rouge">&lt;offset&gt; [operators...] = &lt;range&gt;</code>, where <code class="language-plaintext highlighter-rouge">&lt;offset&gt;</code> is relative to the IP header. For UDP over IPv4, the application payload starts from 28 (20 bytes of IPv4 and 8 bytes of UDP)</li>
		<li><code class="language-plaintext highlighter-rouge">25 &amp; 0xFF = 1:4</code>: The 28th byte is in range <code class="language-plaintext highlighter-rouge">1:4</code>.</li>
		<li><code class="language-plaintext highlighter-rouge">28 &amp; 0xFFFFFF = 0</code>: The 29th to 31th bytes are all zero.</li>
	</ul>
	<p>For IPv6, you just need to increase the offset by 20 (IPv6 header is 40 bytes), so the rule becomes <code class="language-plaintext highlighter-rouge">45 &amp; 0xFF = 1:4 &amp;&amp; 48 &amp; 0xFFFFFF = 0</code>.</p>
	<p>This VPN server is running like a hearse so proofs are left out for brevity.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="networking" /><summary type="html"><![CDATA[Public Wi-Fi and some campus network typically block traffic from unauthenticated clients, but more often allow traffic targeting UDP port 53 to pass through, which is normally used for DNS queries. This feature can be exploited to bypass authentication by connecting to a VPN server that’s also running on UDP 53.]]></summary></entry><entry><title type="html">Vlab 远程教学云桌面</title><link href="https://ibug.io/blog/2023/08/nju-talk/" rel="alternate" type="text/html" title="Vlab 远程教学云桌面" /><published>2023-08-19T00:00:00+00:00</published><updated>2023-08-19T13:50:40+00:00</updated><id>https://ibug.io/blog/2023/08/nju-talk</id><content type="html" xml:base="https://ibug.io/blog/2023/08/nju-talk/"><![CDATA[<section id="title">
		<h1 class="title">Vlab<br>
			远程教学云桌面</h1>
		<p class="date">iBug @ USTC</p>
		<p class="date">2023 年 8 月 19 日<br />
			南京大学</p>
	</section>
	<section id="cover-image">
		<style>
			:root {
			  --r-heading-font-weight: bold;
			}

			.slides section {
			  max-height: 100%;
			}

			li img {
			  vertical-align: middle;
			}

			li+li {
			  margin-top: 0.25em;
			}

			.img-container {
			  width: 100%;
			  height: 100%;

			  display: flex;
			  flex-direction: column;
			  justify-content: center;
			}

			.img-container img {
			  display: block;
			  max-height: 100%;
			  margin: auto !important;
			  object-fit: contain;
			}

			.reveal section>img {
			  display: block;
			  margin: auto !important;
			  max-height: 95vh;
			}

			.border {
			  border: 1px solid black;
			}
		</style>
		<div class="img-container">
			<img src="https://image.ibugone.com/vlab/vlab-in-browser.jpg" />
		</div>
	</section>
	<section id="目录">
		<h2>目录</h2>
		<ol type="1">
			<li>背景</li>
			<li>第一代 Vlab</li>
			<li>第二代 Vlab</li>
			<li>技术分享</li>
			<li>共享灵车</li>
			<li>成果</li>
		</ol>
	</section>
	<section>
		<section id="background">
			<h2>背景</h2>
			<p>计算机实验的环境配置问题：</p>
			<ul>
				<li>学校机房开放时间有限，利用率低</li>
				<li>部分实验软件体积大、对配置要求高（如 Vivado）</li>
				<li>学生使用的系统环境不同，导致安装与使用时出现奇怪的问题</li>
				<li>部分实验环境安装时容易损坏（如双系统安装）</li>
			</ul>
		</section>
		<section id="background-idea">
			<h2>思考</h2>
			<p>能不能通过提供预先配置好实验环境的虚拟机来解决这个问题呢？</p>
			<ul>
				<li>Linux 虚拟机还是 Windows 虚拟机？</li>
				<li>实验软件怎么配？</li>
				<li>给学生分配多少系统资源？主机需要多少硬件配置？</li>
				<li>单位支持：计算机实验教学中心</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="1st-gen">
			<h2>第一代 Vlab</h2>
			<ul>
				<li>2019 年暑假搭建完成<br />
					秋季学期小范围运营</li>
				<li>接入校园网，提供 VNC 连接</li>
				<li>打包虚拟机镜像预装 Vivado 方便实验</li>
			</ul>
		</section>
		<section id="1st-gen-features">
			<h3>平台特点</h3>
			<ul>
				<li>单台 E5 2630 v4 (2S)，<s>64</s> 128 GB 内存，一些固态和机械</li>
				<li>Ubuntu 18.04 + 3.10.0-957.el7🤔 + LXD snap</li>
				<li>lxdbr0 ↔ USTCnet</li>
			</ul>
			<hr />
			<ul>
				<li>校园网接入：可以使用网络通选择出口或从校外连接
					<ul>
						<li><s>也可以挂 Minecraft 服务器、Terraria 服务器、……</s></li>
					</ul>
				</li>
				<li>虚拟机镜像：(Ubuntu 1 GB) + Xfce4 (2 GB) + Vivado (<b>18 GB</b>)
					<ul>
						<li>好在单机有 ZFS 可以用</li>
					</ul>
				</li>
				<li>用 Django 糊了个面板（@taoky），使用统一身份认证登录</li>
			</ul>
		</section>
		<section id="1st-gen-sumup">
			<h3>总结经验</h3>
			<ul>
				<li><s>一台母鸡超卖也卖不动多少啊</s></li>
				<li>避免将用户虚拟机直接连接在校园网上
					<ul>
						<li>这样既不方便使用，也不安全</li>
						<li>机房 IP 早晚会不够用的（3× /24）</li>
						<li>开个 NAT</li>
					</ul>
				</li>
				<li>提供桌面和命令行的统一登录接口，方便用户连接使用</li>
				<li>配备更多实验软件</li>
				<li>完善用户文档</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="2nd-gen">
			<h2>第二代 Vlab</h2>
			<ul>
				<li>2020 年寒假基本配置完成<br />
					春季学期投入使用</li>
				<li>改进了第一代 Vlab 的许多不足点</li>
			</ul>
		</section>
		<section id="2nd-gen-infrastructure">
			<h3>基础设施</h3>
			<ul>
				<li>采购：HPE MSA 1050，Gen10 节点 ×8, 251 交换机</li>
				<li>Ubuntu ❌ Proxmox VE ✔</li>
				<li>iSCSI 存储共享：LVM（no thin provisioning）</li>
				<li>网络：VXLAN、NAT 网关</li>
				<li><s>小修小补的</s> Django 面板</li>
				<li>超卖能力++++</li>
			</ul>
		</section>
		<section id="2nd-gen-network">
			<div class="img-container">
				<img src="https://image.ibugone.com/vlab/network-external-1.png" />
			</div>
		</section>
		<section id="2nd-gen-network-internal">
			<div class="img-container">
				<img src="https://image.ibugone.com/vlab/network-internal.png" />
			</div>
		</section>
		<section id="gateway">
			<h3>年轻人的第一次卵路由实践</h3>
			<ul>
				<li>基础功能：为虚拟机提供 NAT 上网</li>
				<li>基本操作：Debian LXC + 手搓 iproute2 + iptables（其实也没那么复杂）</li>
				<li>DNS + 监控：AdGuard Home</li>
				<li>流量记录：<code>-m conntrack --ctstate NEW -j NFLOG</code>
					<ul>
						<li>没有磁带，不宜全量镜像</li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="lxc-build">
			<h3>稳定可靠的 LXC 镜像构建技术</h3>
			<ul>
				<li>Docker 提供 build environment，PVE 提供 base image</li>
				<li>基于 shell 脚本和 GitHub Actions 的自动化流程
					<ul>
						<li><code>add_file</code>, <code>add_package</code>, <code>run</code> 等“指令”</li>
						<li><s>就差发明一个 <code>Lxcfile</code> DSL 了</s></li>
					</ul>
				</li>
				<li>Repository：<a href="https://github.com/USTC-vlab/labstrap"><i class="fab fa-github"></i>
						USTC-vlab/labstrap</a>
					<ul>
						<li>精神前辈：图书馆查询🐔的 PXE 镜像构建：<a href="https://github.com/ustclug/liimstrap"><i class="fab fa-github"></i>
								ustclug/liimstrap</a></li>
					</ul>
				</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="login">
			<h2>登录方式</h2>
			<p>不开放端口，各种协议都需要转发</p>
			<p>VNC, SSH, and what?</p>
		</section>
		<section id="login-ssh-1">
			<h3>SSH 统一登录</h3>
			<ul>
				<li>SSH 没有 Host header 怎么办：来点 PubkeyAuthentication</li>
				<li><code>ssh <b>-i vm-114514.pem</b> ubuntu@vlab.ustc.edu.cn</code></li>
				<li>鉴权：就像 GitHub / GitLab 一样直接按公钥区分用户（VM）
					<ul>
						<li>Django 提供一个 pubkey → VM IP address 的接口</li>
					</ul>
				</li>
				<li>后端：<code>golang.org/x/crypto/ssh</code>
					<ul>
						<li>初版：Forked from <a href="https://github.com/tg123/sshpiper"><i class="fab fa-github"></i>
								tg123/sshpiper</a></li>
						<li>现在：<a href="https://github.com/USTC-vlab/sshmux"><i class="fab fa-github"></i> USTC-vlab/sshmux</a>
						</li>
						<li>sshpiper 重构了，不好用了 QwQ</li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="login-ssh-2">
			<h3>SSH 统一登录</h3>
			<ul>
				<li>恢复模式（LXC）：<code>ssh <b>recovery</b>@vlab.ustc.edu.cn</code>
					<ul>
						<li>后台转接到 <code>pct enter &lt;vmid&gt;</code></li>
					</ul>
				</li>
				<li>控制台模式（LXC）：<code>ssh <b>console</b>@vlab.ustc.edu.cn</code>
					<ul>
						<li>后台转接到 <code>pct console &lt;vmid&gt;</code></li>
					</ul>
				</li>
				<li>控制台模式（KVM）：<code>ssh <b>serial</b>@vlab.ustc.edu.cn</code>
					<ul>
						<li>后台转接到 <code>qm serial &lt;vmid&gt;</code></li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="login-vnc-1">
			<h3>VNC 统一登录</h3>
			<ul>
				<li>请出神仙：<a href="https://github.com/pdlan"><i class="fab fa-github"></i> pdlan</a>
					<ul>
						<li>逆向了 RealVNC，写了 10,000 行 C艹，到处 <code>co_await</code>，……</li>
						<li>顺带还实现了 TLS 加密</li>
						<li>顺带还实现了……</li>
						<li>外加一个 unix-domain socket 发送管理指令</li>
					</ul>
				</li>
				<li><s>一起来大受震撼吧</s></li>
				<li>使用 VNC 软件连接：
					<ul>
						<li>服务器：<code>vlab.ustc.edu.cn</code>（标准端口 5900/tcp）</li>
						<li>用户名：<code>PB17000001:114514</code>（用户名 + VM ID，如果用户有多个 VM 的话）</li>
					</ul>
				</li>
			</ul>
		</section>
		<section id="login-vnc-2">
			<h3>VNC 统一登录</h3>
			<ul>
				<li>开源贡献：</li>
				<li>
					<img src="https://image.ibugone.com/vlab/tigervnc-pr-pdlan.png" />
					<img src="https://image.ibugone.com/vlab/novnc-pr-pdlan.png" />
				</li>
			</ul>
		</section>
		<section id="login-rdp">
			<h3>RDP 统一登录</h3>
			<ul>
				<li><s>咕咕咕了，Windows VM 支持还没搞定</s></li>
				<li>RDP 一大坨非常起夜级的协议，<s>不是很想逆向</s></li>
				<li><i class="fas fa-fw fa-lightbulb-on"></i> 计划规格：<code>loadbalanceinfo</code></li>
			</ul>
		</section>
		<section id="login-browser">
			<h3>浏览器登录</h3>
			<ul>
				<li>VNC：魔改版 noVNC
					<ul>
						<li>没错，vncmux 顺带还实现了 WebSocket</li>
					</ul>
				</li>
				<li>SSH：Go → WASM</li>
				<li>RDP：从入门到放弃</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="hearses">
			<h2>灵车时间</h2>
		</section>
		<section id="vlab-software-1">
			<h3>磁盘容量</h3>
			<ul>
				<li>一个虚拟机镜像就已经 21 GB 了</li>
				<li>+MATLAB, +Mathematica, +<a href="https://image.ibugone.com/vlab/node_modules-meme.png">node_modules</a></li>
				<li>我们的存储阵列里就有 114514 份 Vivado</li>
			</ul>
		</section>
		<section id="vlab-software-2">
			<h3>Bind mount!</h3>
			<ul>
				<li>local-lvm 开个新卷给 <code>/opt/vlab</code></li>
				<li>mp0: /opt/vlab,mp=/opt/vlab,ro=1</li>
				<li>易于维护：Rsync cron job</li>
			</ul>
		</section>
		<section id="novnc-fun">
			<h3>No... VNC?</h3>
			<p><img src="https://image.ibugone.com/vlab/no-vnc.png" /></p>
		</section>
		<section>
			<img src="https://image.ibugone.com/vlab/502.png" />
		</section>
		<section id="lvm-metadata-full">
			<h3>Everything breaks if pushed too hard...</h3>
			<pre style="font-size: 1em;"><code>VG test 1723 metadata on /dev/sdc1 (521759 bytes) exceeds maximum metadata size (521472 bytes)
Failed to write VG test.</code></pre>
			<p><a href="https://ibug.io/p/52"><i class="fas fa-fw fa-arrow-alt-circle-right"></i> ibug.io/p/52</a></p>
		</section>
		<section id="iowait-spike">
			<h3>IOWait（<code>%wa</code>）午夜准时爆炸</h3>
			<p style="width: 100%; height: 8em; display: flex; justify-content: space-evenly;">
				<img src="https://image.ibugone.com/vlab/iowait-load-average.png" />
				<img src="https://image.ibugone.com/vlab/iowait-iowait.png" />
			</p>
			<p>
				替用户停掉了 <code>man-db.timer</code> 和 <code>apt-daily-upgrade.timer</code>，
				<br />
				给 <code>logrotate.timer</code> 补上了 <code>RandomizedDelaySec=3h</code>。
			</p>
		</section>
		<section id="other-software-gore">
			<h3>其他灵异事件</h3>
			<ul>
				<li>
					一运行备份，网卡就掉了 😦<br />
					解决方法：两边开启 jumbo frame，MTU 拉到 9000 字节
				</li>
				<li>存储服务器的密码掉了</li>
				<li>PVE HA 过于热情（+<code>nofailback</code>）</li>
				<li>Vivado 又双叒叕炸了
					<ol type="1">
						<li><code>LD_PRELOAD</code> += <code>libudev.so.1</code></li>
						<li><code>LD_PRELOAD</code> += <code>libdbus-glib-1.so.2</code></li>
					</ol>
				</li>
			</ul>
		</section>
	</section>
	<section>
		<section id="results">
			<h2>成果</h2>
			<ul>
				<li>自 2020 年春季学期运行至今</li>
				<li>与 <a href="https://fpgaol.ustc.edu.cn/">FPGA Online</a> 和 <a href="https://verilogoj.ustc.edu.cn/">Verilog
						OJ</a> 等项目结合，实现纯在线 FPGA 编程教学</li>
				<li>Grafana：<a href="https://monitor.ibugone.com/grafana/d/2">monitor.ibugone.com/grafana/d/2</a></li>
			</ul>
		</section>
		<section>
			<div class="img-container">
				<img src="https://image.ibugone.com/vlab/containers-2023-08.png" />
			</div>
		</section>
		<section>
			<h3>学习资料</h3>
			<ul>
				<li>用户文档：<a href="https://vlab.ustc.edu.cn/docs/">vlab.ustc.edu.cn/docs</a></li>
				<li>维护文档：<a href="https://vlab.ibugone.com/">vlab.ibugone.com</a></li>
				<li>GitHub Org：<a href="https://github.com/USTC-vlab"><i class="fab fa-github"></i> USTC-vlab</a></li>
			</ul>
		</section>
	</section>
	<section id="outro">
		<h1>谢谢！</h1>
		<p><small>本页面的链接：<a href="https://ibug.io/p/59"><i class="fas fa-fw fa-link"></i> ibug.io/p/59</a></small></p>
	</section>
	]]></content><author><name>iBug</name></author><category term="tags" /><category term="tags" /></entry><entry><title type="html">Prolonging eMMC Life Span with Proxmox VE</title><link href="https://ibug.io/blog/2023/07/prolonging-emmc-life-span-with-proxmox-ve/" rel="alternate" type="text/html" title="Prolonging eMMC Life Span with Proxmox VE" /><published>2023-07-15T00:00:00+00:00</published><updated>2023-07-15T20:32:06+00:00</updated><id>https://ibug.io/blog/2023/07/prolonging-emmc-life-span-with-proxmox-ve</id><content type="html" xml:base="https://ibug.io/blog/2023/07/prolonging-emmc-life-span-with-proxmox-ve/"><![CDATA[<p>Since my blog on <a href="/p/49">installing Proxmox VE on eMMC</a>, there’s been a lot of discussion over the Internet on this. I suspect that Proxmox decided not to include eMMCs in their hardware options by design, as eMMCs typically do not offer the level of endurance as anything better than USB flash drives. Among many concerns, the most important one is the limited number of write cycles that an eMMC can sustain, while Proxmox VE, being an enterprise-grade product, has to constantly write stuff like logs to the storage. I came across <a href="https://fat-nerds.com/dot-nerd/cut-down-proxmox-ve-emmc-sd-read-write/">this blog (fat-nerds.com)</a> on reducing eMMC writes on a Proxmox VE installation on a single-board computer from a Hong Kong guy, so I figure I’d share my ideas here.</p>
	<p>This article will be a remix of the original blog, with some of my own experiences blended in.</p>
	<p>As a courtesy, here’s the disclaimer from the original blog:</p>
	<blockquote>
		<p>警告：下面的設定不應該被應用於有重大價值的伺服器上面！這只是筆者強行在便宜硬件上塞進PVE並以更暴力的方式去為其續命的手段。</p>
	</blockquote>
	<blockquote>
		<p>WARNING: The following settings should not be applied to valuable production servers! This is just a method for the author to force Proxmox VE onto cheap hardware and to prolong its life span.</p>
	</blockquote>
	<h2 id="swap">Disable swap</h2>
	<p>Swap is the mechanism of offloading some memory from physical RAM to disk in order to improve RAM management efficiency. If you have a lot of physical RAM, chances are swap isn’t going to be much helpful while producing a lot of writes to the disk. On a default Proxmox VE installation, the swap size is set from 4 GB to 8 GB, depending on your RAM capacity and disk size.</p>
	<p>You can temporarily disable swap by setting sysctl <code class="language-plaintext highlighter-rouge">vm.swappiness</code> to 0:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>sysctl vm.swappiness<span class="o">=</span>0
</code></pre>
		</div>
	</div>
	<p>Or why not just remove the swap space altogether?</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>swapoff <span class="nt">-a</span>  <span class="c"># disables swap</span>
vim /etc/fstab  <span class="c"># remove the swap entry</span>
lvremove /dev/pve/swap  <span class="c"># remove the swap logical volume</span>
</code></pre>
		</div>
	</div>
	<p>In most cases, you won’t need swap on a Proxmox VE host. If you find yourself needing swap, you should probably consider upgrading your RAM instead.</p>
	<h2 id="logs">System logs</h2>
	<h3 id="move-logs">Move logs to another disk</h3>
	<p>Every system produces logs, but Proxmox VE is particularly prolific on this. In a production environment, you’ll want to keep the logs by storing them on a separate disk (but why is it running on an eMMC in the first place?). So get another reliable disk and migrate the logs:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># assuming the new disk is /dev/sdX</span>
systemctl stop rsyslog

mount /dev/sdX1 /var/log1
rsync <span class="nt">-avAXx</span> /var/log/ /var/log1/
<span class="nb">rm</span> <span class="nt">-rf</span> /var/log
<span class="nb">mkdir</span> /var/log
umount /var/log1
vim /etc/fstab  <span class="c"># add an entry for /dev/sdX1</span>
systemctl daemon-reload  <span class="c"># see notes</span>
mount /var/log

systemctl start rsyslog
</code></pre>
		</div>
	</div>
	<p>Notes on the above commands:</p>
	<ul>
		<li>Rsync is better than <code class="language-plaintext highlighter-rouge">cp</code> if you need to perform a non-trivial copy operation. (The original blog uses <code class="language-plaintext highlighter-rouge">cp</code>.)</li>
		<li>Using <code class="language-plaintext highlighter-rouge">fstab</code> guarantees any mounts are consistent and persistent across reboots.</li>
		<li>
			<p>Why <code class="language-plaintext highlighter-rouge">systemctl daemon-reload</code> after edting <code class="language-plaintext highlighter-rouge">fstab</code>? Because <a href="https://unix.stackexchange.com/q/474743/211239">systemd is sometimes too smart</a> (I got bitten by this once).</p>
		</li>
	</ul>
	<h3 id="disable-logs">Or disable logs altogether</h3>
	<p>On a hobbyist setup, you may be fine with disabling logs altogether.</p>
	<p>The original blog suggests replacing a few file with symlinks to <code class="language-plaintext highlighter-rouge">/dev/null</code>, which I find rather incomplete and ineffective. On my 5-GB-used rootfs, <code class="language-plaintext highlighter-rouge">/var/log</code> takes 1.8 GB, of which <code class="language-plaintext highlighter-rouge">/var/log/journal</code> eats 1.6 GB alone, so systemd journal is the first thing to go. Editing <code class="language-plaintext highlighter-rouge">/etc/systemd/journald.conf</code> and setting <code class="language-plaintext highlighter-rouge">Storage=none</code> will stop its disk hogging, but better yet, you can keep a minimal amount of logs by combining <code class="language-plaintext highlighter-rouge">Storage=volatile</code> and <code class="language-plaintext highlighter-rouge">RuntimeMaxUse=16M</code> (<a href="https://unix.stackexchange.com/a/705057/211239">ref</a>).</p>
	<p>If you’re on Proxmox VE 8+, you can create an “override” file for systemd-journald by adding your customizations to <code class="language-plaintext highlighter-rouge">/etc/systemd/journald.conf.d/override.conf</code>. This will save some trouble when the stock configuration file gets updated and you’re asked to merge the changes.</p>
	<p>For other logs, you can simply replace them with symlinks to <code class="language-plaintext highlighter-rouge">/dev/null</code>. For example:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="nb">ln</span> <span class="nt">-sfn</span> /dev/null /var/log/lastlog
</code></pre>
		</div>
	</div>
	<p>I’m not keen on this method as other logs only comes at a rate of a few hundred MBs per week, so I’d rather keep them around.</p>
	<h2 id="pve-services">Stop certain PVE services</h2>
	<p>The original blog suggests stopping a few non-essential services as they (which I couldn’t verify, nor do I believe so):</p>
	<ul>
		<li>High-Availability-related services (you don’t need HA on a single-node setup):
			<ul>
				<li><code class="language-plaintext highlighter-rouge">pve-ha-lrm</code></li>
				<li><code class="language-plaintext highlighter-rouge">pve-ha-crm</code></li>
			</ul>
		</li>
		<li>Firewall logger: <code class="language-plaintext highlighter-rouge">pvefw-logger</code></li>
		<li>Non-essential and non-PVE services:
			<ul>
				<li>spiceproxy (required for SPICE console, but noVNC is better)</li>
				<li>corosync (required for multi-node setup)</li>
			</ul>
		</li>
	</ul>
	<p>Except for <code class="language-plaintext highlighter-rouge">pvefw-logger</code>, stopping these services will not save you much disk writes as per my experiences.</p>
	<h2 id="rrdcached">Reduce <code class="language-plaintext highlighter-rouge">rrdcached</code> writes</h2>
	<p><code class="language-plaintext highlighter-rouge">rrdcached</code> is the service that stores and provides data for the PVE web interface to display graphs on system resource usage. I have no idea how much writes it produces, so I just relay the optimization given in the original blog.</p>
	<ul>
		<li>Edit <code class="language-plaintext highlighter-rouge">/etc/default/rrdcached</code>:
			<ul>
				<li>Set <code class="language-plaintext highlighter-rouge">WRITE_TIMEOUT=3600</code> so it only writes to disk once per hour.</li>
				<li>Comment out <code class="language-plaintext highlighter-rouge">JOURNAL_PATH</code> so it stops writing journals (not the data itself).</li>
				<li>Add <code class="language-plaintext highlighter-rouge">FLUSH_TIMEOUT=7200</code> (timeout for <code class="language-plaintext highlighter-rouge">flush</code> command, not sure how useful it is).</li>
			</ul>
		</li>
		<li>
			<p>Edit <code class="language-plaintext highlighter-rouge">/etc/init.d/rrdcached</code> for it to pick up the new <code class="language-plaintext highlighter-rouge">FLUSH_TIMEOUT</code> value:</p>
			<p>Find these lines:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span>:+-w<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span><span class="k">}}</span> <span class="se">\</span>
<span class="k">${</span><span class="nv">WRITE_JITTER</span>:+-z<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_JITTER</span><span class="k">}}</span> <span class="se">\</span>
</code></pre>
				</div>
    </div>
			<p>And insert one line for <code class="language-plaintext highlighter-rouge">FLUSH_TIMEOUT</code>:</p>
			<div class="language-shell highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span>:+-w<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_TIMEOUT</span><span class="k">}}</span> <span class="se">\</span>
<span class="k">${</span><span class="nv">FLUSH_TIMEOUT</span>:+-f<span class="p"> </span><span class="k">${</span><span class="nv">FLUSH_TIMEOUT</span><span class="k">}}</span> <span class="se">\</span>
<span class="k">${</span><span class="nv">WRITE_JITTER</span>:+-z<span class="p"> </span><span class="k">${</span><span class="nv">WRITE_JITTER</span><span class="k">}}</span> <span class="se">\</span>
</code></pre>
				</div>
    </div>
		</li>
	</ul>
	<p>After editing both files, restart the service: <code class="language-plaintext highlighter-rouge">systemctl restart rrdcached.service</code></p>
	<h2 id="pvestatd">Stop <code class="language-plaintext highlighter-rouge">pvestatd</code></h2>
	<p><code class="language-plaintext highlighter-rouge">pvestatd</code> provides an interface for hardware information for the PVE system. It shouldn’t produce much writes and stopping it will prevent creation of new VMs and containers, so I don’t recommend stopping it. The original blog probably included this option as a result of a mistake or ignorance.</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>We can see how Proxmox VE is designed to provide enterprise-grade reliability and durability, at the expense of producing lots of disk writes for its various components like system logging and statistics. Based on the above analysis, it seems perfectly reasonable that Proxmox VE decides not to support eMMC storage.</p>
	<p>This blog combines a few tips from the original blog and my own experiences. I hope it helps you with your Proxmox VE setup on any eMMC-backed devices.</p>
	<div class="notice notice--primary">
		<p class="align-center" style="font-size: 1.6em;">But <em>really</em>?</p>
	</div>
	<h2 class="no_toc" id="results">Results</h2>
	<p>There’s one key question left unanswered by everything above: How much writes does Proxmox VE really produce?</p>
	<p>To answer this question, let’s see some of my examples:</p>
	<h3 class="no_toc" id="server-1">Server 1</h3>
	<p>Specs:</p>
	<ul>
		<li>Two enterprise-grade SSDs in RAID 1</li>
		<li>Running since October 2019</li>
		<li>“Master” node in a multi-node cluster, with the entire cluster running over 2,000 VMs and containers (~10 on this host)</li>
	</ul>
	<p>Total writes as of July 2023 (rootfs-only, thanks to <a href="https://unix.stackexchange.com/q/121699/211239">this answer</a>):</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># lrwxrwxrwx 1 root root 7 Jul 12 15:48 /dev/pve/root -&gt; ../dm-4</span>
<span class="c"># cat /sys/fs/ext4/dm-4/lifetime_write_kbytes</span>
17017268104
</code></pre>
		</div>
	</div>
	<p>Result: 4.5 TB annually.</p>
	<h3 class="no_toc" id="server-2">Server 2</h3>
	<p>Specs:</p>
	<ul>
		<li>Two ol’ rusty spinning drives in RAID 1</li>
		<li>Running since January 2022</li>
		<li>Belongs to a multi-node cluster, running around 20 VMs (~3 on this host)</li>
	</ul>
	<p>Total writes as of July 2023 (rootfs-only):</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># lrwxrwxrwx 1 root root 7 Jan 21  2022 /dev/pve/root -&gt; ../dm-1</span>
<span class="c"># cat /sys/fs/ext4/dm-1/lifetime_write_kbytes</span>
2336580629
</code></pre>
		</div>
	</div>
	<p>Result: 1.5 TB annually.</p>
	<h3 class="no_toc" id="server-3">Server 3</h3>
	<p>Specs:</p>
	<ul>
		<li>Lab’s storage server, single SSD for rootfs and ZFS SLOG (ZIL)</li>
		<li>Running since October 2022</li>
		<li>Single-node setup, running 2 VMs</li>
		<li>Data is stored separately</li>
	</ul>
	<p>Total writes as of July 2023:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="c"># smartctl -A /dev/sda</span>
241 Total_LBAs_Written 2849895751
</code></pre>
		</div>
	</div>
	<p><code class="language-plaintext highlighter-rouge">humanize.naturalsize(2849895751 * 512, format="%.2f")</code>: 1.46 TB (≈ 2 TB annually)</p>
	<h3 class="no_toc" id="emmc-write-life">eMMC Write Life</h3>
	<p>This one really depends on the hardware you get. In 2023 virtually every reasonable TLC flash chip should withstand at least 1,000 P/E cycles, so even a pathetic 8 GB eMMC should last around 10 TB of writes, <a href="https://forums.raspberrypi.com/viewtopic.php?t=291808">as that on a Raspberry Pi Compute Module 4</a>.</p>
	<p>If you get anything larger than that, you should be fine expecting it to survive at least 20 TB of writes.</p>
	<h2 class="no_toc" id="real-conclusion">REAL Conclusion</h2>
	<p>Congratulations on reading this far.</p>
	<p>If you managed to hold your paranoia and refrain from putting anything into action, you can now sit back and relax. Unless you’re squeezing hundreds of VMs and containers into a single eMMC-driven board (poor board) without separate storage for VMs, your eMMC is not going to die anytime soon.</p>
	<h2 id="references">References</h2>
	<ul>
		<li>Original blog (Traditional Chinese): <a href="https://fat-nerds.com/dot-nerd/cut-down-proxmox-ve-emmc-sd-read-write/">單板小主機上的Proxmox VE實務：暴力減少eMMC或SD卡的讀寫耗損</a></li>
		<li><a href="https://forums.raspberrypi.com/viewtopic.php?t=291808">CM4 eMMC durability - Terabytes written value (TBW)?</a></li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="server" /><category term="proxmox-ve" /><summary type="html"><![CDATA[Since my blog on installing Proxmox VE on eMMC, there’s been a lot of discussion over the Internet on this. I suspect that Proxmox decided not to include eMMCs in their hardware options by design, as eMMCs typically do not offer the level of endurance as anything better than USB flash drives. Among many concerns, the most important one is the limited number of write cycles that an eMMC can sustain, while Proxmox VE, being an enterprise-grade product, has to constantly write stuff like logs to the storage. I came across this blog (fat-nerds.com) on reducing eMMC writes on a Proxmox VE installation on a single-board computer from a Hong Kong guy, so I figure I’d share my ideas here.]]></summary></entry><entry><title type="html">My automated Daily Health Report infrastructure</title><link href="https://ibug.io/blog/2023/04/checkin-infrastructure/" rel="alternate" type="text/html" title="My automated Daily Health Report infrastructure" /><published>2023-04-23T00:00:00+00:00</published><updated>2023-04-24T00:48:56+00:00</updated><id>https://ibug.io/blog/2023/04/checkin-infrastructure</id><content type="html" xml:base="https://ibug.io/blog/2023/04/checkin-infrastructure/"><![CDATA[<p>Back in the days when the <a href="https://en.wikipedia.org/wiki/Chinese_government_response_to_COVID-19">Zero COVID policy</a> was prevailing, our university introduced a <em>Daily Health Report</em> system. Students and faculty were mandated to submit a daily online form detailing their health status. Noncompliance resulted in denied campus access, and in more stringent times, forced quarantine. Thanks to the comprehensive lockdown of campuses, our activity were strictly confined. Consequently, our daily data submission were pratically invariant. It’s a colossal waste of effort to do it manually (with some anecdotes later on), so I opted to automate the process.</p>
	<p>As the policies evolved, our school’s reporting platform also underwent changes. I had to update the reporting script multiple times with new features to align those of the reporting platform.</p>
	<p>Much like my <a href="/blog/2023/01/overengineering-adventofcode/">previous article</a>, there’s a significant distinction between making something work and making it work with elegance. So in this article, I’ll share my infrastructure for the automated daily report system, and delve into some design options and decisions I made in the way.</p>
	<h2 id="script">The reporting script</h2>
	<p>Writing a script is about the easiest thing in the whole system with the least technical complexity. Anyone with basic scripting abilities can do it well, so I <a href="https://github.com/iBug/thu-checkin">open-sourced mine</a>. It only takes a few minutes to open the Developer Tools on your browser, identify the request originating from the [Submit] button, copy its payload out and put that into a script, and it’s ready to service. If anything marginally fancy were to be added, it’d be saving certain data to a separate file so that others can adopt the script more easily.</p>
	<p>The next thing is to run the script every day at a desired time. A common solution is to use Cron that is simple and easy. <a href="https://wiki.archlinux.org/title/systemd/Timers">Systemd timers</a> is a modern alternative offering more features at the expense of a more complex configuration. I chose the latter for its <code class="language-plaintext highlighter-rouge">RandomizedDelaySec</code> option, so that the script won’t be run at the exact same time every day.</p>
	<p>At the beginning I also had a sample GitHub Actions workflow file so that others can fork my repository and start automating their reports with minimal effort. However, I scrapped it later on realizing it’s against GitHub’s ToS.</p>
	<p><img src="/image/server/checkin-1.png" alt="First step" /></p>
	<h2 id="status">Status report</h2>
	<p>The next thing is to stay informed of whether the script is working properly. Logging in to the server and reading logs every day is not fun. Assuming that it worked and ending up being denied entry to the school is even worse. So it’d be nice to be notified of everything it does.</p>
	<p>A common choice is via email, but it’s lacking a bit of timeliness. I chose Telegram because I’m actively using it and it provides a bot API. Adding <code class="language-plaintext highlighter-rouge">python-telegram-bot</code> to the script and a few lines of code, I can get a notification on my Telegram every time the script runs.</p>
	<p>My actual setup differs slightly, with an extra component between the script and the bot: an AWS Lambda serverless function. I did this for two reasons:</p>
	<ul>
		<li>Minor reason: Telegram servers (<code class="language-plaintext highlighter-rouge">api.telegram.org</code>) is not directly accessible from mainland China for well-known reasons.</li>
		<li><strong>Major reason</strong>: I already have a <a href="/blog/2021/02/github-webhook-on-aws-lambda/">GitHub webhook</a> running on AWS Lambda. It is much less involved to add another URL handler to that function and reuse the existing codebase, like credentials and message formatting. This allows me to simplify the notification to a single <code class="language-plaintext highlighter-rouge">requests.post</code>.</li>
	</ul>
	<p><img src="/image/server/checkin-2.png" alt="Second step" /></p>
	<p>As a bonus feature, I also send the error message and the line number in case of an exception, so that I can quickly identify the problem before investigating the logs.</p>
	<blockquote>
		<p><strong>[THU Checkin]</strong> Success: 2023-02-24 20:42:23<br />
			Checkin: Success<br />
			Apply: Success</p>
	</blockquote>
	<blockquote>
		<p><strong>[THU Checkin]</strong> ❌ <strong>Error</strong>: 2023-02-25 20:05:46<br />
			AttributeError: ‘NoneType’ object has no attribute ‘group’<br />
			On <code class="language-plaintext highlighter-rouge">checkin.py</code> line 67</p>
	</blockquote>
	<h2 id="image">Uploading images</h2>
	<p>Sometime later, our school began to demand regular uploads of our <a href="https://en.wikipedia.org/wiki/Health_Code">health QR code</a>. The QR code is generated by a govermental mobile app whose retrieval is, unfortunately, difficult to automate. Before stepping over the line of producing fake QR codes, I decided to take the screenshots manually and have my script upload them to the reporting platform. The good news is, there’s no measures on the platform to validate the uploaded images, so uploading an outdated screenshot yields no consequences most of the time, and I don’t have to constantly update the screenshots for the script.</p>
	<p>Image uploading is nothing new to the <code class="language-plaintext highlighter-rouge">requests</code> Python library, but I have to deliver the files from my phone somehow. Options to transfer files from an Android phone to a Linux server are abundant, and for me I found SMB the most convenient. <a href="https://play.google.com/store/apps/details?id=com.speedsoftware.rootexplorer">Root Explorer</a> is the file manager that I’ve been using for a decade, so I could just set up Samba on my server to receive the files from it.</p>
	<blockquote>
		<p><strong>[THU Checkin]</strong> Success: 2023-02-25 08:33:36<br />
			Checkin: Success<br />
			Apply: Success<br />
			Image 1: Skipped<br />
			Image 2: Success<br />
			Image 3: Success</p>
	</blockquote>
	<p><img src="/image/server/checkin-3.png" alt="Third step" /></p>
	<p>Alternatively, I could have my Telegram bot accept the images and forward them to the server. This would be more convenient in terms of using, but much less in coding as I didn’t have any existing code in my Telegram bot that handles images. Meanwhile, I already had Samba running on my server so I in fact did not set it up anew.</p>
	<h2 id="security">Securing the server</h2>
	<p>At this point everything is operational, with one detail missing: The SMB protocol is not known for being secure. Exposing the SMB port to the Internet is prone to troubles and connecting to a VPN every time is not convenient. Luckily I have Clash for Android running on my phone 24/7 that I can use to proxy Root Explorer. I set up a shadowsocks-libev server and configured Clash to route traffic targeting my server through it, and then closed the SMB port in my server firewall.</p>
	<p>There’s a noteworthy thing about Clash: It’s a rule-based proxy software that reads configurations. My airport<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" class="footnote" rel="footnote">1</a></sup> service provides their configuration through a subscription URL, but Clash for Android doesn’t support editing subscribed config. Another background story comes up here: I have another Lambda function serving as my own Clash config subscription. It fetches the airport config and modifies it to my preferences, and then serves it to Clash. It also makes updating the config easier, as I can just update the Lambda function code and the changes will be reflected in Clash.</p>
	<p>Fun fact: My custom subscription is also used with Clash for Windows on my computer, which helped me completely bypass two RCE vulnerabilities (<a href="https://github.com/Fndroid/clash_for_windows_pkg/issues/2710">1</a>, <a href="https://github.com/advisories/GHSA-rq24-vhfq-6v9x">2</a>).</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>After all this complexity, here’s what I’ve got:</p>
	<p><img src="/image/server/checkin-infra.png" alt="Final state" /></p>
	<p>The script runs every day at a random time in a configured time span, and I get a notification on Telegram regardless of whether it succeeds or fails. If the script fails I also have the required information to look into it. The script also uploads the health QR code screenshots to the reporting platform, and I can update the images from my phone through a secured connection.</p>
	<p>Of all these tasks, only taking the screenshots and uploading them to the server is manual, denoted in the image by blue arrows. All black arrows are automated and require no attention to function.</p>
	<p>As the zero-COVID policy <a href="https://en.wikipedia.org/wiki/Chinese_government_response_to_COVID-19#2022_outbreaks_and_end_of_zero-COVID_policy">came crumbling down</a> in December 2022, our school also put an end to the daily health reporting system. As a result, I can safely share my setup here without fearing repercussions. I hope this article brings you some inspiration for your next automation project.</p>
	<div class="notice--primary">
		<h4 class="no_toc" id="anecdote">Anecdote</h4>
		<p>During the days around the strictest lockdown of campuses, all students’ requests for outgoing were manually reviewed by two levels of authority, with the second level being the dean. Our department consists of over 2,000 students that kept submitting requests every day. Needless to say, many staff weren’t happy about this, and the dean in particular. We were once asked to stop phoning her as she was already processing the requests from 7 AM to 11 PM every day. To everyone’s relief, the reviewing process was cancelled in a few days and requests were automatically approved thereafter.</p>
	</div>
	<div class="footnotes" role="doc-endnotes">
		<ol>
			<li id="fn:1" role="doc-endnote">
				<p>Shadowsocks service providers are commonly called “airports” because the icon of Shadowsocks is a paper plane, and every provider has multiple “plane servers” that you can use. <a href="#fnref:1" class="reversefootnote" role="doc-backlink">&#8617;</a></p>
			</li>
		</ol>
	</div>
	]]></content><author><name>iBug</name></author><category term="tech" /><category term="server" /><category term="networking" /><category term="development" /><summary type="html"><![CDATA[Back in the days when the Zero COVID policy was prevailing, our university introduced a Daily Health Report system. Students and faculty were mandated to submit a daily online form detailing their health status. Noncompliance resulted in denied campus access, and in more stringent times, forced quarantine. Thanks to the comprehensive lockdown of campuses, our activity were strictly confined. Consequently, our daily data submission were pratically invariant. It’s a colossal waste of effort to do it manually (with some anecdotes later on), so I opted to automate the process.]]></summary></entry><entry><title type="html">Overengineering Advent of Code 2022</title><link href="https://ibug.io/blog/2023/01/overengineering-adventofcode/" rel="alternate" type="text/html" title="Overengineering Advent of Code 2022" /><published>2023-01-08T00:00:00+00:00</published><updated>2023-01-09T02:17:24+00:00</updated><id>https://ibug.io/blog/2023/01/overengineering-adventofcode</id><content type="html" xml:base="https://ibug.io/blog/2023/01/overengineering-adventofcode/"><![CDATA[<p><em>Advent of Code</em> (<a href="https://en.wikipedia.org/wiki/Advent_of_Code">Wikipedia</a>, <a href="https://adventofcode.com/">link</a>) is an annual event that releases a programming puzzle every day from December 1 to December 25. It’s a great chance to learn a new language or practice your skills.</p>
	<p><img src="/image/adventofcode-2022.png" alt="Image" /></p>
	<p>Considering that all the puzzles are designed to be lightweight, meaning that if implemented correctly, they’re solvable in no more than a few seconds with a reasonably small memory footprint, I picked Go as my language of choice. Go has been my preference over Python for a while, for being compiled into machine code and thus more performant, and a decent set of standard libraries.</p>
	<h2 id="puzzles">Notes on puzzles</h2>
	<p>The first 10 puzzles are very easy and doesn’t even require special knowledge. They’re practically just text processing and simulation, so there aren’t many comments to be made.</p>
	<ul>
		<li>
			<p>Day 2: While it’s straightforward to implement a rock-paper-scissors game using <code class="language-plaintext highlighter-rouge">switch</code>es or lookup tables, noticing that shape <code class="language-plaintext highlighter-rouge">i+1</code> beats shape <code class="language-plaintext highlighter-rouge">i</code> allows us to simplify the code in an obscure way.</p>
			<p>For example, I implemented the “shape score” as <code class="language-plaintext highlighter-rouge">int(s[2] - 'W')</code>, and the “outcome score” as <code class="language-plaintext highlighter-rouge">(4 + int(s[2]-'X') - int(s[0]-'A')) % 3 * 3</code> for the first part. For the second part, the “shape score” is now <code class="language-plaintext highlighter-rouge">1 + (int(s[0]-'A')+int(s[2]-'X')+2)%3</code>, and the “outcome score” is <code class="language-plaintext highlighter-rouge">int(s[2]-'X') * 3</code>.</p>
			<p>This is certainly not the most readable code, but it’s a good example of how to use math to simplify code. Less code = less bugs, and if you’re really crazy about that, you can always add unit tests to ensure that the code doesn’t break unexpectedly. That’s not my style, though.</p>
		</li>
	</ul>
	<p>Starting from Day 11, the puzzles become more interesting. Some math or data structures are required to solve them.</p>
	<ul>
		<li>Day 11: The first part is plain simulation, but the second part can easily run the numbers out of range if you don’t manage them properly. Actually, modulo by the <a href="https://en.wikipedia.org/wiki/Least_common_multiple">least common multiple</a> of the divisors is a good way to keep them down.</li>
		<li>Day 14, 15 and 23: With a large coordinate space but limited elements, it’s a better idea to use a map or set instead of contiguous memory.</li>
		<li>Day 17 part 2: Running a simulation for 1000000000000 rounds is certainly not feasible, but it’s possible to find a pattern from the first 10000 or so rounds, and calculate the result from there.</li>
		<li>Day 18 part 2: Finding internal holes would be difficult, but <a href="https://en.wikipedia.org/wiki/Flood_fill">flood filling</a> from the outside is an alternative approach.</li>
		<li>Day 19 part 2: Even if searching for the “next robot to make” can’t keep the search space small, pruning near the leaves (i.e. stop searching in the last few minutes) can still cut it down by a large factor. This is the only way that I managed to bring the run time below 1 second.</li>
		<li>Day 20 part 2: Again simulating for so many 811589153 steps is not feasible, so like Day 11 part 2, it’s important to find a correct modulo.</li>
		<li>Day 21 part 2: At first this seems like tremendous work, but I made a bold assumption that the equation is linear (degree = 1), which turned out to be true. This enabled me to use very simple math to solve it.</li>
		<li>Day 22 is my favorite puzzle. Finding an algorithm to fold a flat layout into a cube is far from easy, so I hard-coded it for my input. (It seems like everyone is getting the same layout.) Such a two-layer <code class="language-plaintext highlighter-rouge">switch</code> statement is prone to bugs and took me the longest time to debug.</li>
		<li>Day 25: To my surprise, the puzzle is missing a part 2. Maybe the author is getting on a vacation?</li>
	</ul>
	<p>Finally, a magic trick that I discovered from Reddit for Day 15 part 2: Observing that the only uncovered space must be adjacent to multiple covered areas, examining the intersections of the edges of the beacons’ coverage areas produces a tiny search space. While it’s intuitive to build upon part 1’s solution, this discovery leads to a lightspeed solution.</p>
	<h2 id="engineering">Engineering the project</h2>
	<p>In fact, rushing to the puzzles was not even the first thing. I did not come across the event until my friend <a href="https://www.taoky.moe/">taoky</a> recommended it to me. He was already halfway through the puzzles (<a href="https://github.com/taoky/adventofcode">his <i class="fab fa-fw fa-github"></i> repository</a>) and had set himself a set of rules, including one where “<em>all solutions should take reasonable time and memory usage</em>”. We discussed various methods to measure the time and memory usage, when he set it forth that it was not easy to add measurements to every single program.</p>
	<p>Based on our discussion, I decided I would leave room for measurements when designing the project. So the first decision was to reuse code as much as possible within the project. For example, I’d like all solutions to share the same “peripherals” like the <code class="language-plaintext highlighter-rouge">main</code> function. This way if I want to add an extra feasure like performance measurement, I only need to do it once.</p>
	<p>The next decision was to compile solutions for all puzzles into a single binary. Go is not known for producing small binaries due to static linking, so having separate binaries for each solutions implies a non-trivial amount of unnecessary disk space. Another reason is that due to Go’s package design, it’s more complex to selectively compile individual files than to compile all files together (the “package”). With a <code class="language-plaintext highlighter-rouge">go.mod</code> file present, <code class="language-plaintext highlighter-rouge">go build</code> conveniently compiles all files in the same directory.</p>
	<p>With that in mind, <a href="https://github.com/iBug/AdventOfCode/commit/73715a64f7e860dffa63382ed3dff14b8d4ae60d">here</a>’s the first commit of the project. In addition to the code itself, two more design ideas can be seen:</p>
	<ul>
		<li>Individual solutions are in their own files, calling <code class="language-plaintext highlighter-rouge">RegisterSolution</code> in their <code class="language-plaintext highlighter-rouge">init</code> functions to register themselves. Also, the solution function takes a single <code class="language-plaintext highlighter-rouge">io.Reader</code> interface as input, so that providing input can be more flexible if needed.</li>
		<li>If multiple input files are provided, the solution function sees a concatenation of all of them, similar to a number of common Unix tools. However, this little care was later decided to be unnecessary, and only a single input file would be processed.</li>
	</ul>
	<p>Now with the project structure in place, I started working on the solutions. <a href="https://github.com/iBug/AdventOfCode/commit/4b695648807b47818e60ab19d246ff61183c7ce2">The second commit</a> added my solution for Day 1 part 1, and it followed the designed structure like this:</p>
	<div class="language-go highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="p">(</span> <span class="o">...</span> <span class="p">)</span>

<span class="k">func</span> <span class="n">Solution1_1</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">reader</span><span class="p">)</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>

<span class="k">func</span> <span class="n">init</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"1-1"</span><span class="p">,</span> <span class="n">Solution1_1</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>While the first few days’ solutions were pretty ordinary, my design began to prosper when I started working on Day 5 part 2. The only difference between part 1 and part 2 is whether moving a stack of crates maintains or reverses their order. Compared to the common one-source-file-per-solution design, I can now reuse almost the whole function from part 1, and abstract the difference into a function parameter. This is how <code class="language-plaintext highlighter-rouge">day5.go</code> looks like after <a href="https://github.com/iBug/AdventOfCode/commit/fe63dc98e36b70c0f9ffb779eadffc34d2a7b80b">adding part 2</a>:</p>
	<div class="language-go highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">package</span> <span class="n">main</span>

<span class="k">import</span> <span class="p">(</span> <span class="o">...</span> <span class="p">)</span>

<span class="k">func</span> <span class="n">init</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"5-1"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution5</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Move5_1</span><span class="p">)</span> <span class="p">})</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"5-2"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution5</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="n">Move5_2</span><span class="p">)</span> <span class="p">})</span>
<span class="p">}</span>

<span class="k">func</span> <span class="n">Move5_1</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>
<span class="k">func</span> <span class="n">Move5_2</span><span class="p">(</span><span class="o">...</span><span class="p">)</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>

<span class="k">func</span> <span class="n">Solution5</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">,</span> <span class="n">moveFunc</span> <span class="k">func</span><span class="p">(</span><span class="o">...</span><span class="p">))</span> <span class="p">{</span> <span class="o">...</span> <span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>For Day 6, <a href="https://github.com/iBug/AdventOfCode/commit/cf19fad5b05e992dfdab9f6abcf2a87c4b808d7a">the benefit</a> is even more prominent:</p>
	<div class="language-go highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="k">func</span> <span class="n">init</span><span class="p">()</span> <span class="p">{</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"6-1"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution6</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="m">4</span><span class="p">)</span> <span class="p">})</span>
    <span class="n">RegisterSolution</span><span class="p">(</span><span class="s">"6-2"</span><span class="p">,</span> <span class="k">func</span><span class="p">(</span><span class="n">r</span> <span class="n">io</span><span class="o">.</span><span class="n">Reader</span><span class="p">)</span> <span class="p">{</span> <span class="n">Solution6</span><span class="p">(</span><span class="n">r</span><span class="p">,</span> <span class="m">14</span><span class="p">)</span> <span class="p">})</span>
<span class="p">}</span>
</code></pre>
		</div>
	</div>
	<p>Had I not designed the project this way, I would have to duplicate the whole function for part 2 only to change a single parameter, making things much more error-prone.</p>
	<h3 id="measurements">Adding measurements</h3>
	<p>Given the project design above, adding measurements is much simpler than it would have been if I had adopted the one-source-file-per-solution layout. It boils down to just two things:</p>
	<ul>
		<li>
			<p>A command-line flag to enable measurements:</p>
			<div class="language-go highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="n">flag</span><span class="o">.</span><span class="n">BoolVar</span><span class="p">(</span><span class="o">&amp;</span><span class="n">fShowPerformance</span><span class="p">,</span> <span class="s">"p"</span><span class="p">,</span> <span class="no">false</span><span class="p">,</span> <span class="s">"show performance information"</span><span class="p">)</span>
</code></pre>
				</div>
    </div>
		</li>
		<li>
			<p>Adding <code class="language-plaintext highlighter-rouge">time.Now()</code> and <code class="language-plaintext highlighter-rouge">time.Since()</code> around the call to the solution function:</p>
			<div class="language-go highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="n">start</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">Now</span><span class="p">()</span>
<span class="n">fn</span><span class="p">(</span><span class="n">r</span><span class="p">)</span>
<span class="n">duration</span> <span class="o">:=</span> <span class="n">time</span><span class="o">.</span><span class="n">Since</span><span class="p">(</span><span class="n">startTime</span><span class="p">)</span>
</code></pre>
				</div>
    </div>
			<p>… as well as displaying the result:</p>
			<div class="language-go highlighter-rouge">
				<div class="highlight">
					<pre class="highlight"><code><span class="k">if</span> <span class="n">fShowPerformance</span> <span class="p">{</span>
    <span class="n">fmt</span><span class="o">.</span><span class="n">Fprintf</span><span class="p">(</span><span class="n">os</span><span class="o">.</span><span class="n">Stderr</span><span class="p">,</span> <span class="s">"</span><span class="se">\n</span><span class="s">Duration: %s</span><span class="se">\n</span><span class="s">"</span><span class="p">,</span> <span class="n">duration</span><span class="p">)</span>
<span class="p">}</span>
</code></pre>
				</div>
    </div>
		</li>
	</ul>
	<p>Measuring memory usage is a bit more complicated. Go’s memory profiling doesn’t provide a simple “max usage in this session” metric, so I have to resort to OS-specific methods. On Linux, for the time being, I use <code class="language-plaintext highlighter-rouge">getrusage(2)</code> with <code class="language-plaintext highlighter-rouge">RUSAGE_SELF</code>, as two other known methods (using Cgroup and polling <code class="language-plaintext highlighter-rouge">/proc/self/status</code>) either require forking an extra process or add significant overhead and engineering complexity.</p>
	<p>Now the program can produce a short summary of the performance when running a solution:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">$</span><span class="w"> </span>./adventofcode <span class="nt">-p</span> 1-1 2022/inputs/1.txt
<span class="go">71780

Time: 875µs, Memory: 7.8 MiB
</span></code></pre>
		</div>
	</div>
	<p>There’s one caveat here: The “Max RSS” value returned by <code class="language-plaintext highlighter-rouge">getrsage(2)</code> is the peak memory usage during the whole program’s lifetime, starting from when it’s forked from the parent process, when it inherits all mapped pages (resident set). Using an interactive Bash gives a minimum value of around 7.7 MiB, while using <code class="language-plaintext highlighter-rouge">sh -c './adventofcode -p'</code>, adding a level indirection, reduces the starting size to 1.2 MiB.</p>
	<h3 id="multi-year">Adding multi-year support</h3>
	<p>Up until now, the project has a flat layout with no subdirectories, and all Go source files start with <code class="language-plaintext highlighter-rouge">package main</code>. This is because I did not plan to support multiple years at the beginning. However, as I started working on puzzles from 2021, I realized that I need a better structure to support multiple years without worrying about namespace issues, like both years having a <code class="language-plaintext highlighter-rouge">Solution1_1</code> function.</p>
	<p>Moving each year’s solutions into a subdirectory is a natural choice. However, <code class="language-plaintext highlighter-rouge">go build</code> doesn’t pick up subdirectories by default, so I have to find a way to make it work. There are also some minor name searching issues, like <code class="language-plaintext highlighter-rouge">RegisterSolution</code> being defined in <code class="language-plaintext highlighter-rouge">main.go</code> but used in every solution file.</p>
	<p>After a bit of trial-and-error, I <a href="https://github.com/iBug/AdventOfCode/commit/36b256c41897633bae53a1ca4c39476e0af9d858">carried out</a> the following changes:</p>
	<ul>
		<li>Split out the “solution registry” into a <code class="language-plaintext highlighter-rouge">common</code> subdirectory, making it a separate package that can be imported by each year’s package.
			<ul>
				<li>Each year’s package should import just <code class="language-plaintext highlighter-rouge">common.RegisterSolution</code>, possibly wrapping it up to add a custom “year identifier” (this was <a href="https://github.com/iBug/AdventOfCode/commit/7f7080aae1df181ec2b16eafc3bbd214610914c4">implemented</a> right after).</li>
			</ul>
		</li>
		<li>Move all solution files into a <code class="language-plaintext highlighter-rouge">2022</code> subdirectory, and change the package name to just <code class="language-plaintext highlighter-rouge">year</code> (because I don’t expect this directory to be imported and used with the package name).</li>
		<li>Add <code class="language-plaintext highlighter-rouge">import _ "adventofcode/2022"</code> in <code class="language-plaintext highlighter-rouge">main.go</code> for each year’s subdirectory.</li>
	</ul>
	<p>In subsequent commits, I implemented “year selection” (e.g. choosing between the solutions <code class="language-plaintext highlighter-rouge">2021/1-1</code> and <code class="language-plaintext highlighter-rouge">2022/1-1</code>) as well as more listings (e.g. <code class="language-plaintext highlighter-rouge">./adventofcode 2021/</code> to list all solutions for 2021).</p>
	<p>With this in place, I can now add solutions for 2021 without worrying about name conflicts. For convenience, I also added auto-searching for input files in the current directory, so I can just run <code class="language-plaintext highlighter-rouge">./adventofcode 2021/1-1</code> to run the solution for Day 1 part 1 of 2021.</p>
	<h2 id="epilogue">Epilogue</h2>
	<p>At this point, the project has successfully deviated from a collection of solutions to small-but-interesting puzzles, and has become more like a general-purpose tool for this kind of events. Nevertheless, it’s a fun journey as a software engineering practice, in addition to solving the puzzles themselves.</p>
	<p>Looking at these paths I’ve taken, it is manifest that the initial decisions in the right direction are highly contributory in easing the development process, particularly when I’m coming back later to add a new global feature. This experience once again emphasizes the importance and advantages of having a clear idea of the project before starting to write code, as well as keeping the code in an extensible and maintainable fashion.</p>
	]]></content><author><name>iBug</name></author><category term="development" /><summary type="html"><![CDATA[Advent of Code (Wikipedia, link) is an annual event that releases a programming puzzle every day from December 1 to December 25. It’s a great chance to learn a new language or practice your skills.]]></summary></entry><entry><title type="html">Recovering a Minecraft world from a crash, the technician way</title><link href="https://ibug.io/blog/2022/11/recover-minecraft-world/" rel="alternate" type="text/html" title="Recovering a Minecraft world from a crash, the technician way" /><published>2022-11-27T00:00:00+00:00</published><updated>2022-12-18T23:54:35+00:00</updated><id>https://ibug.io/blog/2022/11/recover-minecraft-world</id><content type="html" xml:base="https://ibug.io/blog/2022/11/recover-minecraft-world/"><![CDATA[<p>While a friend was building an automatic brewing pipeline, our <a href="https://www.curseforge.com/minecraft/modpacks/create-astral">Create: Astral</a> server crashed and wouldn’t start again. At first we thought it’d be easy to restore our world from a backup, only to find that the automatic backup mechanism wasn’t working at all due to misconfiguration. The last manual backup was taken a few days ago, so reverting to that backup means a lot of progress loss, which is undesirable for us.</p>
	<h2 id="gathering-information">Gathering information</h2>
	<p>If at all possible, we would like to salvage this broken world, so we start with an investigation of the crash log. It appears to be an infinite recursion with Create.</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:219)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
at com.simibubi.create.foundation.item.ItemHelper.extract(ItemHelper.java:223)
</code></pre>
		</div>
	</div>
	<p>None of us has any knowledge in Java, but fortunately with <a href="https://www.curseforge.com/minecraft/mc-mods/not-enough-crashes">Not Enough Crashes (Fabric)</a>, the crash log gives a hint on which block is going wrong, as shown below:</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>-- Block entity being ticked --
Details:
        Name: create:funnel // com.simibubi.create.content.logistics.block.funnel.FunnelTileEntity
        Block: Block{create:brass_funnel}[extracting=true,facing=north,powered=false]
        Block location: World: (-15,65,172), Section: (at 1,1,12 in -1,4,10; chunk contains blocks -16,-64,160 to -1,319,175), Region: (-1,0; contains chunks -32,0 to -1,31, blocks -512,-64,0 to -1,319,511)
        Block: Block{create:brass_funnel}[extracting=true,facing=north,powered=false]
        Block location: World: (-15,65,172), Section: (at 1,1,12 in -1,4,10; chunk contains blocks -16,-64,160 to -1,319,175), Region: (-1,0; contains chunks -32,0 to -1,31, blocks -512,-64,0 to -1,319,511)
Stacktrace:
        at net.minecraft.class_2818$class_5563.method_31703(class_2818.java:670)
        at net.minecraft.class_2818$class_5564.method_31703(class_2818.java:713)
        ...
</code></pre>
		</div>
	</div>
	<p>One idea now surfaces: If we can remove or replace with something else the offending block, we can probably fix the save with minimal progress loss.</p>
	<p>The following information can be summarized from the above portion of the crash log:</p>
	<ul>
		<li>The offending block is a Brass Funnel from Create</li>
		<li>It’s located at (-15,65,172), in chunk (-1,10), section 4 (a vertical 16×16×16 section)</li>
		<li>The block coordinates are (1,1,12) <strong>within the section</strong></li>
		<li>The region is (-1,0), meaning that the file that contains is <code class="language-plaintext highlighter-rouge">r.-1.0.mca</code>.</li>
	</ul>
	<p>Recalling that Minecraft worlds are also saved in NBT format, I try opening the region file with <a href="https://github.com/C4K3/nbted">nbted</a>, a tool that I previously used to tamper with player data. However, it complains:</p>
	<div class="language-text highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>Error: Unable to parse r.-1.0.mca, are you sure it's an NBT file?
        caused by: Unknown compression format where first byte is 0
</code></pre>
		</div>
	</div>
	<p>This indicates that the region file is not a single, complete NBT file, so I have to look for another tool to handle this.</p>
	<h2 id="reading-the-world-file">Reading the world file</h2>
	<p>Google-ing for <code class="language-plaintext highlighter-rouge">minecraft region site:github.com</code> leads me to Fenixin/Minecraft-Region-Fixer, of which an included <a href="https://github.com/Fenixin/Minecraft-Region-Fixer/tree/master/nbt">NBT library</a> seems promising. I grab this repository and take the <code class="language-plaintext highlighter-rouge">nbt</code> directory out, throwing away everything else.</p>
	<p>The <code class="language-plaintext highlighter-rouge">region.py</code> file provides a <code class="language-plaintext highlighter-rouge">RegionFile</code> class that can be used to access region files, so I start playing with it:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="kn">import</span> <span class="n">nbt</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span> <span class="o">=</span> <span class="n">nbt</span><span class="p">.</span><span class="n">region</span><span class="p">.</span><span class="nc">RegionFile</span><span class="p">(</span><span class="sh">'</span><span class="s">r.-1.0.mca</span><span class="sh">'</span><span class="p">)</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">r</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span><span class="mi">10</span><span class="p">)</span>
<span class="c"># Traceback (most recent call last):
</span><span class="go">KeyError: (-1, 10)
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">r</span><span class="p">.</span><span class="nf">get_chunk</span><span class="p">(</span><span class="mi">31</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="go">&lt;NBTFile with TAG_Compound('') at 0x7f8a8d014eb0&gt;
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">c</span> <span class="o">=</span> <span class="n">_</span>
</code></pre>
		</div>
	</div>
	<p>So this Python library arranges chunks by offset <em>within the region file</em>. That’s fine.</p>
	<p>Now that I have access to an NBT tag, it’s time to study its structure. The <a href="https://minecraft.fandom.com/wiki/Chunk_format">Chunk format</a> page from Minecraft Wiki is the ultimate reference here.</p>
	<p>I know that <code class="language-plaintext highlighter-rouge">c</code> holds the “root tag” of the chunk I’m looking for. This is easily verified:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">c</span><span class="p">[</span><span class="sh">'</span><span class="s">xPos</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="sh">'</span><span class="s">zPos</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span>
<span class="go">(-1, 10)
</span></code></pre>
		</div>
	</div>
	<p>I find the vertical section containing the offending block:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">s</span> <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="n">c</span><span class="p">[</span><span class="sh">'</span><span class="s">sections</span><span class="sh">'</span><span class="p">]</span> <span class="k">if</span> <span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">Y</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span> <span class="o">==</span> <span class="mi">4</span><span class="p">]</span>
<span class="go">[&lt;TAG_Compound('') at 0x7f8a8d44c1c0&gt;]
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span> <span class="o">=</span> <span class="n">_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
</code></pre>
		</div>
	</div>
	<p>The <a href="https://minecraft.fandom.com/wiki/Anvil_file_format">Anvil file format</a> page shows that block data is ordered in YZX order, so I try to find the block data from the <code class="language-plaintext highlighter-rouge">data</code> key:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">][</span><span class="mi">256</span> <span class="o">+</span> <span class="mi">12</span><span class="o">*</span><span class="mi">16</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]</span>
<span class="go">72624976668147841
</span></code></pre>
		</div>
	</div>
	<p>… which is, unfortunately not something I can decipher.</p>
	<p>I look closely to the description of the <code class="language-plaintext highlighter-rouge">data</code> tag:</p>
	<blockquote>
		<p><strong>A packed array</strong> of 4096 indices pointing to the palette, stored in an array of 64-bit integers. […] All indices are the same length: the minimum amount of bytes required to represent the largest index in the palette. […] Since 1.16, the indices are not packed across multiple elements of the array, meaning that if there is no more space in a given 64-bit integer for the next index, it starts instead at the first (lowest) bit of the next 64-bit element.</p>
	</blockquote>
	<p>So not only was that number <em>not</em> for a single block, but also was I looking for a wrong index. I need to inspect the block palette first:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">palette</span><span class="sh">'</span><span class="p">])</span>
<span class="go">95
</span><span class="gp">&gt;&gt;&gt; </span><span class="p">[(</span><span class="n">i</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">b</span> <span class="ow">in</span> <span class="nf">enumerate</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">palette</span><span class="sh">'</span><span class="p">])</span>
<span class="gp">... </span><span class="w"> </span><span class="k">if</span> <span class="n">b</span><span class="p">[</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span> <span class="o">==</span> <span class="sh">"</span><span class="s">create:brass_funnel</span><span class="sh">"</span><span class="p">]</span>
<span class="go">[(55, &lt;TAG_Compound('') at 0x7f8a8d49d120&gt;), (77, &lt;TAG_Compound('') at 0x7f8a8d49ff40&gt;)]
</span></code></pre>
		</div>
	</div>
	<p>There are two indices allotted for the funnel block, but at this point it cannot be determined which one is correct. I look inside the packed <code class="language-plaintext highlighter-rouge">data</code> array, recalculating the index from the block coordinates using information above:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">][(</span><span class="mi">256</span> <span class="o">+</span> <span class="mi">12</span><span class="o">*</span><span class="mi">16</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">9</span><span class="p">]</span>
<span class="go">3963735054717000501
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">i</span> <span class="o">=</span> <span class="n">_</span>
</code></pre>
		</div>
	</div>
	<p>Because there are 95 blocks in the palette, 7 bits is enough to hold an index, and a 64-bit integer holds 9 indices. The calculation can be verified by the following:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="nf">len</span><span class="p">(</span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">])</span>
<span class="go">456
</span><span class="gp">&gt;&gt;&gt; </span><span class="mi">456</span> <span class="o">*</span> <span class="mi">9</span>
<span class="go">4104
</span><span class="c"># just slightly over 4096
</span></code></pre>
		</div>
	</div>
	<p>Now I unpack that large integer into 9 indices, and try to translate them into blocks:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="p">[(</span><span class="n">i</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="n">x</span><span class="p">))</span> <span class="o">&amp;</span> <span class="mh">0x7F</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>
<span class="go">[53, 54, 46, 1, 1, 1, 1, 1, 55]
</span><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">palette</span><span class="sh">'</span><span class="p">][((</span><span class="n">i</span> <span class="o">&gt;&gt;</span> <span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="n">x</span><span class="p">))</span> <span class="o">&amp;</span> <span class="mh">0x7F</span><span class="p">)][</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span>
<span class="gp">... </span><span class="w"> </span><span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">9</span><span class="p">)]</span>
<span class="go">['create:spout',
 'create:mechanical_pump',
 'tconstruct:seared_drain',
 'minecraft:air',
 'minecraft:air',
 'minecraft:air',
 'minecraft:air',
 'minecraft:air',
 'create:brass_funnel']
</span></code></pre>
		</div>
	</div>
	<p>It starts to make sense now. I can recall a <a href="https://tinkers-construct.fandom.com/wiki/Smeltery">Smeltery</a> structure that we built together near this area.</p>
	<h2 id="replacing-the-block">Replacing the block</h2>
	<p>The offending Brass Funnel is the last index within this packed 64-bit integer. I can replace it with air (index = 1) using bit manipulation:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">ii</span> <span class="o">=</span> <span class="n">i</span> <span class="o">^</span> <span class="p">((</span><span class="mi">55</span> <span class="o">^</span> <span class="mi">1</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="mi">8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">ii</span>
<span class="go">72624976668891957
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">][(</span><span class="mi">256</span> <span class="o">+</span> <span class="mi">12</span><span class="o">*</span><span class="mi">16</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="n">ii</span>
</code></pre>
		</div>
	</div>
	<p>Now I try to save the file, only to find that <code class="language-plaintext highlighter-rouge">nbt.region.RegionFile</code> offers no <code class="language-plaintext highlighter-rouge">.save()</code> or <code class="language-plaintext highlighter-rouge">.write()</code> methods:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="p">.</span><span class="o">&lt;</span><span class="n">TAB</span><span class="o">&gt;&lt;</span><span class="n">TAB</span><span class="o">&gt;</span>
<span class="go">f.STATUS_CHUNK_IN_HEADER           f.get_chunk_coords()
f.STATUS_CHUNK_MISMATCHED_LENGTHS  f.get_chunks()
f.STATUS_CHUNK_NOT_CREATED         f.get_metadata()
f.STATUS_CHUNK_OK                  f.get_nbt(
f.STATUS_CHUNK_OUT_OF_FILE         f.get_size()
f.STATUS_CHUNK_OVERLAPPING         f.get_timestamp(
f.STATUS_CHUNK_ZERO_LENGTH         f.header
f.chunk_count()                    f.iter_chunks()
f.chunk_headers                    f.iter_chunks_class()
f.chunkclass                       f.loc
f.close()                          f.metadata
f.closed                           f.size
f.file                             f.unlink_chunk(
f.filename                         f.write_blockdata(
f.get_blockdata(                   f.write_chunk(
f.get_chunk(
</span></code></pre>
		</div>
	</div>
	<p class="notice--primary"><i class="fas fa-fw fa-lightbulb"></i> In my original attempt, I took a diversion from the right track, forgetting that each chunk comes in a single-root NBT tag, and that the region file <em>packs</em> multiple chunks into a single file. I only realized that the file format was different from what I expected at first after multiple failed attempts to modify the file using a hex editor.</p>
	<p>Reading <a href="https://minecraft.fandom.com/wiki/Region_file_format">Region file format</a>, I learn that each chunk is compressed (using Zlib) separately and stored together in the region file, and that <code class="language-plaintext highlighter-rouge">f.write_chunk</code> is the method I am looking for.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="p">.</span><span class="nf">write_chunk</span><span class="p">(</span><span class="mi">31</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
<span class="go">&gt;&gt;&gt;
</span></code></pre>
		</div>
	</div>
	<p>The file size is reduced by some 60 KB. Considering that compression algorithm provides no guarantee on the size of the compressed data, this is not an indicator whether the file’s going well or not. The only way to verify is to load the world and check the result in game.</p>
	<p>With uncertainty, I make a backup of the broken world, and replace <code class="language-plaintext highlighter-rouge">r.-1.0.mca</code> with my modified copy. The server now starts normally, and I can see the brass funnel disappeared.</p>
	<p><img src="/image/minecraft/createastral-1.jpg" alt="Block removed" /></p>
	<h2 id="extra-tests">Extra tests</h2>
	<p>To convince myself that I have successfully changed the correct block, I decide that I need to replace it with something visible, not just air. I look inside the palette of the section, and found a few blocks available for use.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">palette</span><span class="sh">'</span><span class="p">][</span><span class="mi">25</span><span class="p">][</span><span class="sh">'</span><span class="s">Name</span><span class="sh">'</span><span class="p">]</span>
<span class="go">minecraft:grass_block
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">ii</span> <span class="o">=</span> <span class="n">i</span> <span class="o">^</span> <span class="p">((</span><span class="mi">55</span> <span class="o">^</span> <span class="mi">25</span><span class="p">)</span> <span class="o">&lt;&lt;</span> <span class="p">(</span><span class="mi">7</span><span class="o">*</span><span class="mi">8</span><span class="p">))</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">s</span><span class="p">[</span><span class="sh">'</span><span class="s">block_states</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">data</span><span class="sh">'</span><span class="p">][(</span><span class="mi">256</span> <span class="o">+</span> <span class="mi">12</span><span class="o">*</span><span class="mi">16</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span> <span class="o">//</span> <span class="mi">9</span><span class="p">]</span> <span class="o">=</span> <span class="n">ii</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">f</span><span class="p">.</span><span class="nf">write_chunk</span><span class="p">(</span><span class="mi">31</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="n">c</span><span class="p">)</span>
</code></pre>
		</div>
	</div>
	<p>I then copy the file back to the server, and start it again. As expected, the block at that coordinate is now a grass block.</p>
	<p><img src="/image/minecraft/createastral-2.jpg" alt="Block replaced with Grass Block" /></p>
	<h2 id="additional-information">Additional information</h2>
	<p>According to <a href="https://minecraft.fandom.com/wiki/Chunk_format">Chunk format</a>, block entities are stored in a <code class="language-plaintext highlighter-rouge">block_entity</code> tag under the root tag of the chunk. It’s possible to inspect the block entity data for the offending Brass Funnel, using information provided under the <a href="https://minecraft.fandom.com/wiki/Chunk_format#Block_entity_format">Block entity format</a> section.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt;</span><span class="w"> </span><span class="nf">len</span><span class="p">(</span><span class="n">c</span><span class="p">[</span><span class="sh">'</span><span class="s">block_entities</span><span class="sh">'</span><span class="p">])</span>
<span class="go">420
</span><span class="gp">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">c</span><span class="p">[</span><span class="sh">'</span><span class="s">block_entities</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">][</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span>
<span class="go">-14
</span></code></pre>
		</div>
	</div>
	<p>So the coordinates for block entities are absolute, not relative to the chunk. Now find the Brass Funnel:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">be</span> <span class="k">for</span> <span class="n">be</span> <span class="ow">in</span> <span class="n">c</span><span class="p">[</span><span class="sh">'</span><span class="s">block_entities</span><span class="sh">'</span><span class="p">]</span>
<span class="gp">... </span><span class="w"> </span><span class="k">if</span> <span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">x</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span> <span class="o">==</span> <span class="o">-</span><span class="mi">15</span> <span class="ow">and</span> <span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">y</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span> <span class="o">==</span> <span class="mi">65</span> <span class="ow">and</span> <span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">z</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span> <span class="o">==</span> <span class="mi">172</span><span class="p">]</span>
<span class="go">[&lt;TAG_Compound('') at 0x7f8a8d4afd30&gt;]
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span> <span class="o">=</span> <span class="n">_</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">.</span><span class="nf">keys</span><span class="p">()</span>
<span class="go">['z', 'x', 'TransferCooldown', 'id', 'y', 'FilterAmount', 'keepPacked', 'Filter']
</span></code></pre>
		</div>
	</div>
	<p>More than half of these keys are familiar: They are common to all block entities. Another one <code class="language-plaintext highlighter-rouge">TransferCooldown</code> is also present for Hoppers. The names of the remaining two tags are self-explanatory.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">FilterAmount</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span>
<span class="go">2
</span><span class="gp">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">]</span>
<span class="go">&lt;TAG_Compound('Filter') at 0x7f8a8d1000a0&gt;
</span><span class="gp">&gt;&gt;&gt;</span><span class="w"> </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">].</span><span class="nf">keys</span><span class="p">()</span>
<span class="go">['id', 'tag', 'Count']
</span></code></pre>
		</div>
	</div>
	<p>So the <code class="language-plaintext highlighter-rouge">Filter</code> key is an item. In my case it’s a <a href="https://create.fandom.com/wiki/Filter">Filter</a> (normal filter, crafted with Iron Nuggets). The contents of the filter can be further inspected:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">].</span><span class="nf">keys</span><span class="p">()</span>
<span class="go">['RespectNBT', 'Blacklist', 'Items']
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Blacklist</span><span class="sh">'</span><span class="p">].</span><span class="n">value</span>
<span class="go">1
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">]</span>
<span class="go">&lt;TAG_Compound('Items') at 0x7f8a8d100070&gt;
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">].</span><span class="nf">keys</span><span class="p">()</span>
<span class="go">['Size', 'Items']
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">]</span>
<span class="go">2 entries of type TAG_Compound
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">]</span>
<span class="go">&lt;TAG_Compound('') at 0x7f8a8d1003d0&gt;
</span><span class="gp">&gt;&gt;&gt; </span><span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">][</span><span class="mi">0</span><span class="p">].</span><span class="nf">keys</span><span class="p">()</span>
<span class="go">['Slot', 'id', 'Count']
</span><span class="gp">&gt;&gt;&gt; </span><span class="p">[</span><span class="n">it</span><span class="p">[</span><span class="sh">'</span><span class="s">id</span><span class="sh">'</span><span class="p">]</span> <span class="k">for</span> <span class="n">it</span> <span class="ow">in</span> <span class="n">be</span><span class="p">[</span><span class="sh">'</span><span class="s">Filter</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">tag</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">][</span><span class="sh">'</span><span class="s">Items</span><span class="sh">'</span><span class="p">]]</span>
<span class="go">[create:cinder_flour, minecraft:glass_bottle]
</span></code></pre>
		</div>
	</div>
	<p>Now the mystery has been completely uncovered. The Brass Funnel is configured to take everything but Cinder Flour and Glass Bottles, 2 at a time. Considering that the Depot behind is part of a brewing system, there will be brewed Potions, which are unstackable. A friend helped us find the GitHub issue <a href="https://github.com/Fabricators-of-Create/Create/issues/570"><i class="fab fa-github"></i> Create#570</a>, confirming that we ran into the same bug as reported in that thread.</p>
	<h2 id="epilogue">Epilogue</h2>
	<p>The use of block/item names since Java Edition 1.7.2 (<a href="https://minecraft.fandom.com/wiki/Java_Edition_13w37a">13w37a</a>) hinted that block/item IDs would eventually become dynamic, which actually took place in <a href="https://minecraft.fandom.com/wiki/Java_Edition_1.13/Flattening">the Flattening</a> in Java Edition 1.13. The smart use of the “palette + array of indices” paves the way for mods and future expansions to add new blocks without having to worry about the block ID limit, which is also reminiscent of the <a href="https://en.wikipedia.org/wiki/BMP_file_format#Color_table">color table</a> in 8-bit (256 colors) BMP bitmap images.</p>
	<p>Contrary to player data (<code class="language-plaintext highlighter-rouge">playerdata/*.dat</code>), the region file is a lot more complicated. Thanks to the large fan base of Minecraft, libraries for handling the file format are readily available. I am inclined to believe that a few steps taken and decisions made here are critical to the success of salvaging our save.</p>
	<ul>
		<li>First and foremost, checking the logs: We know which block is going wrong, and <em>have faith in ourselves that we can fix it</em>.</li>
		<li>Looking in the correct direction: Instead of using a complete “world edit” tool, we decide to find some library on GitHub and improvise from there.</li>
		<li>Reading the documentation carefully and in detail.</li>
		<li>Doing math correctly (LOL…)</li>
	</ul>
	<p>Finally, I want to credit my friend <a href="https://sirius1242.github.io/">sirius</a> for his unsurpassed knowledge of Minecraft, without whose help I would not have been able to take on this wonderful adventure.</p>
	]]></content><author><name>iBug</name></author><category term="games" /><category term="minecraft" /><summary type="html"><![CDATA[While a friend was building an automatic brewing pipeline, our Create: Astral server crashed and wouldn’t start again. At first we thought it’d be easy to restore our world from a backup, only to find that the automatic backup mechanism wasn’t working at all due to misconfiguration. The last manual backup was taken a few days ago, so reverting to that backup means a lot of progress loss, which is undesirable for us.]]></summary></entry><entry><title type="html">Paper Reading: Are You Sure You Want to Use MMAP in Your Database Management System?</title><link href="https://ibug.io/blog/2022/11/paper-reading-cidr2022-crotty/" rel="alternate" type="text/html" title="Paper Reading: Are You Sure You Want to Use MMAP in Your Database Management System?" /><published>2022-11-05T00:00:00+00:00</published><updated>2022-11-27T19:48:20+00:00</updated><id>https://ibug.io/blog/2022/11/paper-reading-cidr2022-crotty</id><content type="html" xml:base="https://ibug.io/blog/2022/11/paper-reading-cidr2022-crotty/"><![CDATA[<p>Paper reading for [CIDR 2022] <em>Are You Sure You Want to Use MMAP in Your Database Management System?</em> by Crotty et al.</p>
	<p>This paper highlights the problems with using MMAP in database management systems.</p>
	<h2 id="background">Background</h2>
	<p>MMAP is a POSIX system call that transparently maps file content to process memory (the virtual address space of a process). This allows programmers to simplify the logical structure of program by leveraging the OS page cache as a replacement for a manually-maintained buffer pool.</p>
	<p>A typical MMAP procedure goes as follows:</p>
	<figure class="">
		<img src="/image/papers/mmap-procedure.png" alt="A typical MMAP procedure" />
		<figcaption>
			A typical MMAP procedure
		</figcaption>
	</figure>
	<ol>
		<li>A process calls <code class="language-plaintext highlighter-rouge">mmap()</code> for an open file.</li>
		<li>The OS reserves part of the process’s virtual address space, but does <em>not</em> load the file from disk. The process receives a pointer to the mapped address.</li>
		<li>The process accesses the file using that pointer.</li>
		<li>The OS tries to load the page, but no valid mapping exists, which results in a page fault.</li>
		<li>The OS loads the file from disk to physical RAM.</li>
		<li>The OS adds an entry to the page table of the process, mapping the virtual address to the physical address.</li>
		<li>The initiating CPU caches this new page entry in its <a href="https://en.wikipedia.org/wiki/Translation_lookaside_buffer">Translation Lookaside Buffer (TLB)</a> for faster future accesses.</li>
	</ol>
	<p>A process can map as much data from files as the virtual address space permits, and the OS does all the dirty work behind the scenes.</p>
	<p>Files loaded this way count towards the OS page cache (shows in htop as both <code class="language-plaintext highlighter-rouge">RES</code> and <code class="language-plaintext highlighter-rouge">SHR</code>), so the OS must evict pages when physical memory fills up. During page eviction, the OS must ensure that:</p>
	<ul>
		<li>Dirty (modified) pages are written back to disk (if applicable).</li>
		<li>TLBs of all CPU cores are flushed. This is called <em>TLB shootdown</em>.</li>
	</ul>
	<p>Even though disk writes can be avoided on read-only workloads, TLB shootdowns are unavoidable. Worse, since modern CPUs do <em>not</em> provide TLB coherence, flushing TLBs is a costly operation.</p>
	<h3 id="posix-api">Related POSIX APIs</h3>
	<ul>
		<li><code class="language-plaintext highlighter-rouge">mmap()</code> maps a file to memory. The <code class="language-plaintext highlighter-rouge">MAP_SHARED</code> flag allows changes to be (eventually) persisted back to disk, while the <code class="language-plaintext highlighter-rouge">MAP_PRIVATE</code> flag indicates that modifications are discarded (private to the process). These flags cannot be changed after the mapping is created.</li>
		<li><code class="language-plaintext highlighter-rouge">madvise()</code> provides hints to the OS about how the mapped file will be accessed.
			<ul>
				<li>With <code class="language-plaintext highlighter-rouge">MADV_NORMAL</code>, (at least for Linux) loads 32 pages (128 KiB) for every page fault.</li>
				<li>With <code class="language-plaintext highlighter-rouge">MADV_RANDOM</code>, the OS only loads the exact missing page.</li>
				<li>With <code class="language-plaintext highlighter-rouge">MADV_SEQUENTIAL</code>, the OS loads more pages in advance.</li>
			</ul>
		</li>
		<li><code class="language-plaintext highlighter-rouge">mlock()</code> locks the mapped file in physical memory, preventing the OS from evicting it. It does not, however, prevent the OS from flushing dirty pages to disk.</li>
		<li><code class="language-plaintext highlighter-rouge">msync()</code> flushes any modifications to the file back to disk.</li>
	</ul>
	<h2 id="problems">Problems</h2>
	<h3 id="transactional-safety">Transactional safety</h3>
	<p>One important feature that DBMS provides is transactional safety, which is commonly referred to as <a href="https://en.wikipedia.org/wiki/ACID">the <em>ACID</em> properties</a>. Using MMAP on database files poses a threat to theses properties, as OS can transparently flush dirty pages to disk at any time, which the DBMS is has no control over.</p>
	<p>To work around this problem, the paper summarizes three kinds of approaches:</p>
	<ol>
		<li>
			<p><strong>OS copy-on-write</strong></p>
			<p>The first approach maps the same file twice, one with <code class="language-plaintext highlighter-rouge">MAP_SHARED</code> and the other with <code class="language-plaintext highlighter-rouge">MAP_PRIVATE</code>. Any modification is first made to the private mapping, and then synchronized to the shared mapping. To maintain consistency, extra measures like a <a href="https://en.wikipedia.org/wiki/Write-ahead_logging">write-ahead log (WAL)</a> are often used together.</p>
			<p>A noticeable problem with this approach is that as the database is being accessed, the DBMS will eventually end up with two full copies of the file in memory. While it’s possible to periodically shrink the private workspace, it adds extra complexity to the DBMS.</p>
		</li>
		<li>
			<p><strong>Userspace copy-on-write</strong></p>
			<p>The second approach is similar to the first, but instead of <code class="language-plaintext highlighter-rouge">mmap</code>-ing the file twice, the “private workspace” is maintained manually as a separate buffer. This approach is more flexible in terms of memory efficiency and manageability.</p>
		</li>
		<li>
			<p><a href="https://en.wikipedia.org/wiki/Shadow_paging"><strong>Shadow paging</strong></a></p>
			<p>Shadow paging is a traditional copy-on-write technique. The DBMS keeps two copies of the database file, one for the current version and the other for the next version. When a transaction is committed, the DBMS simply swaps the files.</p>
			<p>One downside is obvious: the DBMS must maintain two copies of the database file, which is not ideal for large databases. Even though it is possible to keep only the delta between the two versions, and only maintain the primary and shadow page tables, it introduces more fragmentation and requires careful bookkeeping.</p>
			<p>Additionally, as commitments happens on the whole-file level, this method does not scale well with write concurrency.</p>
		</li>
	</ol>
	<h3 id="io-stalls">I/O stalls</h3>
	<p>With traditional file I/O, the DBMS can use asynchronous I/O to avoid blocking the CPU.</p>
	<p>However, with MMAP, as the OS evict pages in the background transparently, any access to the mapped file may block the thread. Despite having <code class="language-plaintext highlighter-rouge">mlock()</code>, it provides limited mitigation as the amount of locked pages is bounded. While <code class="language-plaintext highlighter-rouge">madvise()</code> helps with OS prefetching decisions, the control is still very coarse.</p>
	<p>Last but not least, while it’s possible to spawn an extra background thread to prefetch pages, the added complexity defeats the purpose of using MMAP in the first place.</p>
	<h3 id="error-handling">Error handling</h3>
	<p>For DBMS with page-level checksums (to prevent disk corruption), the DBMS must revalidate the checksums after <em>every</em> read, as it has no way to know whether the same page has been evicted and re-read from disk.</p>
	<p>For DBMS written in memory-unsafe languages like C (which is quite common), a bad pointer write can silently corrupt the database. With a traditional buffer pool, defensive measures can be implemented to avoid writing corrupted data to disk.</p>
	<p>Finally, with traditional <code class="language-plaintext highlighter-rouge">read()</code>/<code class="language-plaintext highlighter-rouge">write()</code>, error handling resides in the same place as the I/O code. With MMAP, however, error handling must be done through a cumbersome <code class="language-plaintext highlighter-rouge">SIGBUS</code> handler.</p>
	<h3 id="performance-issues">Performance issues</h3>
	<p>While it is a common sense that MMAP is more performant than traditional file I/O by eliminating the system calls and extra memory copies, experiments suggest otherwise. Three issues are pointed out:</p>
	<ul>
		<li>Page table contention (it’s one single data structure for the whole process)</li>
		<li>Single-threaded page eviction (Linux: <code class="language-plaintext highlighter-rouge">kswapd</code>)</li>
		<li>TLB shootdowns (see above)</li>
	</ul>
	<h2 id="experimental-results">Experimental results</h2>
	<div class="notice--primary">
		<h4 class="no_toc" id="note-on-odirect"><i class="fas fa-fw fa-lightbulb"></i> Note on <code class="language-plaintext highlighter-rouge">O_DIRECT</code></h4>
		<p>The FIO test uses the <code class="language-plaintext highlighter-rouge">O_DIRECT</code> flag to bypass the OS page cache. For a more detailed explanation, see <a href="https://stackoverflow.com/q/5055859/5958455">this Stack Overflow question</a>.</p>
	</div>
	<p>The paper presents two kinds of tasks: Random reading and sequential reading, to represent two typical kinds of database workload: <a href="https://www.ibm.com/cloud/blog/olap-vs-oltp">OLTP and OLAP</a>.</p>
	<figure class="">
		<img src="/image/papers/crotty-randread-iops.png" alt="IOPS by time for random read" />
		<figcaption>
			Random read - IOPS
		</figcaption>
	</figure>
	<figure class="">
		<img src="/image/papers/crotty-randread-tlbshootdowns.png" alt="TLB shootdowns by time for random read" />
		<figcaption>
			Random read - TLBshootdowns
		</figcaption>
	</figure>
	<p>It is apparent that it doesn’t take long before MMAP can’t sustain its performance, which is due to the page cache filling up. The OS must work hard on evicting pages, which worsens the situation.</p>
	<figure class="">
		<img src="/image/papers/crotty-seqread-1ssd.png" alt="Bandwidth by time for single-SSD sequential read" />
		<figcaption>
			Sequential read - 1 SSD
		</figcaption>
	</figure>
	<figure class="">
		<img src="/image/papers/crotty-seqread-10ssds.png" alt="Bandwidth by time for 10-SSD sequential read" />
		<figcaption>
			Sequential read - 10 SSDs
		</figcaption>
	</figure>
	<p>With sequential read, the performance gap is larger as disk bandwidth grows. While <code class="language-plaintext highlighter-rouge">fio</code> can almost saturate the bandwidth from 10 SSDs, MMAP’s performance stayed nearly the same. The authors attribute this to the single-threaded page eviction.</p>
	<h2 id="conclusion">Conclusion</h2>
	<p>In the final section, the paper makes an ironic comment, suggesting two cases when you <em>maybe</em> can use MMAP in a database product:</p>
	<ul>
		<li>Your working set (or the entire database) fits in memory and the workload is read-only.</li>
		<li>
			<p>You need to rush a product to the market and do not care about data consistency or long-term engineering headaches.</p>
		</li>
	</ul>
	]]></content><author><name>iBug</name></author><category term="paper-reading" /><summary type="html"><![CDATA[Paper reading for [CIDR 2022] Are You Sure You Want to Use MMAP in Your Database Management System? by Crotty et al.]]></summary></entry><entry><title type="html">LVM metadata exceeds maximum metadata size, now what next?</title><link href="https://ibug.io/blog/2022/06/lvm-metadata-full/" rel="alternate" type="text/html" title="LVM metadata exceeds maximum metadata size, now what next?" /><published>2022-06-19T00:00:00+00:00</published><updated>2022-06-19T22:06:07+00:00</updated><id>https://ibug.io/blog/2022/06/lvm-metadata-full</id><content type="html" xml:base="https://ibug.io/blog/2022/06/lvm-metadata-full/"><![CDATA[<p>An LVM volume group (VG) on our Proxmox VE cluster has failed to create new logical volumes, reporting that its metadata was full. At first this appears to be easy, “fine I’ll just add more space for metadata”, but it quickly revealed to be an versity to struggle through.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">root@iBug-Server:~#</span><span class="w"> </span>lvcreate <span class="nt">-L</span> 4M <span class="nt">-n</span> test-1721 <span class="nb">test</span>
<span class="go">  VG test 1723 metadata on /dev/sdc1 (521759 bytes) exceeds maximum metadata size (521472 bytes)
  Failed to write VG test.
</span><span class="gp">root@iBug-Server:~#</span><span class="w"> </span><span class="c"># wut?</span>
</code></pre>
		</div>
	</div>
	<h2 id="problems">Problems</h2>
	<p>It isn’t hard to imagine that, just like regular disks need a partition table, LVM also needs its “partition table”, called <em>LVM metadata</em>, to store its information about PVs, VGs and LVs. It grows with the complexity of a VG, like number of PVs and configuration of LVs.</p>
	<p>The metadata size and capacity of a PV and a VG can be inspected with <code class="language-plaintext highlighter-rouge">pvdisplay</code> and <code class="language-plaintext highlighter-rouge">vgdisplay</code>, respectively.</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">root@iBug-Server:~#</span><span class="w"> </span>pvdisplay <span class="nt">-C</span> <span class="nt">-o</span> name,mda_size,mda_free
<span class="go">  PV         PMdaSize  PMdaFree
  /dev/sdc1   1020.00k        0
</span><span class="gp">root@iBug-Server:~#</span><span class="w"> </span>vgdisplay <span class="nt">-C</span> <span class="nt">-o</span> name,mda_size,mda_free
<span class="go">  VG   VMdaSize  VMdaFree
  test  1020.00k        0
</span></code></pre>
		</div>
	</div>
	<p>The metadata area (whence <code class="language-plaintext highlighter-rouge">mda</code>) is where LVM stores volume information. The trouble comes from the fact that LVM MDA has multiple oddities going against intuition, which adds to the complexity of findin a solution.</p>
	<h3 id="1-metadata-is-an-ambiguous-term">1. “Metadata” is an ambiguous term</h3>
	<p>If you just go ahead and search for “LVM metadata size”, you’ll be surprised to see how irrelevant the search results are. In fact, they’re about “thin pool metadata”, which is a discrete LV usually named <code class="language-plaintext highlighter-rouge">poolname_tmeta</code>.</p>
	<p>In fact, the correct answer is in the man page, which should show up as the first Google result, <a href="https://man7.org/linux/man-pages/man8/pvcreate.8.html"><code class="language-plaintext highlighter-rouge">pvcreate(8)</code></a>. This is where I discovered the use of <code class="language-plaintext highlighter-rouge">pvs</code> and <code class="language-plaintext highlighter-rouge">vgs</code> to get the sizes.</p>
	<h3 id="2-the-default-mda-size-is-fixed">2. The default MDA size is fixed</h3>
	<p>Contrary to common expectations, the default value for MDA size is <em>fixed</em> and does not scale with PV size or VG size. This is explained in the man page, right above <code class="language-plaintext highlighter-rouge">pvs -o mda_size</code>.</p>
	<p>This is not the case, however, for LVM Thin Pools. It’s not known what the design considerations are behind this.</p>
	<h3 id="3-the-size-of-the-mda-cannot-be-changed-after-creation">3. The size of the MDA cannot be changed after creation</h3>
	<p>As many would probably have, I also thought that “fine, I’ll just expand the size for the MDA”, and started digging through Google and relevant man pages. Another quarter-hour was spent trying to find how to do this, only to find that it can only be set at the creation of the PV. This was confirmed by <a href="https://forum.proxmox.com/threads/cannot-create-more-snapshot-without-deleting-some-olds-one.110112/">this Proxmox forum post</a>.</p>
	<h3 id="4-reducing-metadata-copies-does-not-free-up-space">4. Reducing “metadata copies” does not free up space</h3>
	<p>There’s also a <code class="language-plaintext highlighter-rouge">pvmetadatacopies</code> option listed in both <code class="language-plaintext highlighter-rouge">vgchange(8)</code> and <code class="language-plaintext highlighter-rouge">pvchange(8)</code>, which appears tempting to give a try. Unfortunately, opposite to intuition again, this does not free up half of the MDA space. Setting it to 1 down from the default 2 produces no visible changes.</p>
	<h2 id="finding-the-solution">Finding the solution</h2>
	<p>At this point I had figured out a silhouette for the problem I was facing: A VG on a single PV, fixed MDA size, no room to free up any metadata.</p>
	<p>Fortunately, the shared SAN target supports “overcommitting”, meaning I can have an extra LUN with little effort. Given that the utilized storage is slightly over 50%, it’s not possible to move data onto the new LUN. Even if there were enough free space, moving data would take an infeasible amount of time. Ideally this new LUN shouldn’t be too large, to minimize possible aftermath should the underlying disk group goes full.</p>
	<p>So, how can this trouble be overcome, with the help of a new LUN?</p>
	<hr />
	<p>Digging into this level of details, Google is unable to help, so I had to resort to man pages, if I did not have to check the source codes.</p>
	<p>Looking at <code class="language-plaintext highlighter-rouge">pvchange(8)</code>, the only modifiable property of an existing PV is <code class="language-plaintext highlighter-rouge">metadataignore</code>. It instructs LVM to ignore the MDA for a PV.</p>
	<p>A possible solution has arisen: Create a new PV with large enough MDA, merge it into the VG, and disable metadata storage on the old PV.</p>
	<h2 id="solution">Solution</h2>
	<p>I created a new LUN in the storage server’s dashboard and loaded it onto all servers in the cluster using <code class="language-plaintext highlighter-rouge">iscsiadm</code>:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>iscsiadm <span class="nt">-m</span> session <span class="nt">--rescan</span>
</code></pre>
		</div>
	</div>
	<p>The rescan may have some delay so I continued monitoring it for a minute before <code class="language-plaintext highlighter-rouge">/dev/sdd</code> showed up on all hosts.</p>
	<p>Now I turn the new block device into a PV and add it to the problematic VG:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>pvcreate <span class="nt">--metadatasize</span> 64m /dev/sdd
vgextend <span class="nb">test</span> /dev/sdd
</code></pre>
		</div>
	</div>
	<p>Partly to my surprise, a warning popped up:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>VG <span class="nb">test </span>1723 metadata on /dev/sdc1 <span class="o">(</span>521615 bytes<span class="o">)</span> exceeds maximum metadata size <span class="o">(</span>521472 bytes<span class="o">)</span>
WARNING: Failed to write an MDA of VG test.
Volume group <span class="s2">"test"</span> successfully extended
</code></pre>
		</div>
	</div>
	<p>This one isn’t hard to understand: The VG metadata must record the identifiers of all participating PVs, so adding a PV means more metadata to be stored.</p>
	<p>So before pulling this off, I had to remove a LV temporarily. I had a few laying around for testing purposes, so finding one to get rid of was not hard. After that I could repeat the <code class="language-plaintext highlighter-rouge">vgextend</code> command without a single warning.</p>
	<p>Next I exclude the original PV from storing metadata:</p>
	<div class="language-shell highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code>pvchange <span class="nt">--metadataignore</span> y /dev/sdc1
</code></pre>
		</div>
	</div>
	<p>Now I can add another LV inside this VG without error:</p>
	<div class="language-console highlighter-rouge">
		<div class="highlight">
			<pre class="highlight"><code><span class="gp">root@iBug-Server:~#</span><span class="w"> </span>lvcreate <span class="nt">-L</span> 1M <span class="nt">-n</span> test-1721 <span class="nb">test</span>
<span class="go">  Rounding up size to full physical extent 4.00 MiB
  Logical volume "test-1721" created.
</span><span class="gp">root@iBug-Server:~#</span><span class="w"> </span>pvs <span class="nt">-o</span> name,mda_size,mda_free
<span class="go">  PV         PMdaSize  PMdaFree
  /dev/sdc1   1020.00k        0
  /dev/sdd     &lt;65.00m   &lt;32.00m
</span></code></pre>
		</div>
	</div>
	<h2 id="caveats">Caveats</h2>
	<p>LVM by default stores an identical copy of the metadata on every PV that belongs to the same VG. Using this “solution”, the complete metadata is only stored on the newly created PV. You certainly want to use reliable storage for this new PV as it’s now a <a href="https://en.wikipedia.org/wiki/Single_point_of_failure">SPOF</a> of the whole VG.</p>
	<p>If in any case you want a copy of the metadata for inspection or to recover a failed VG (hope you don’t need to do that), LVM maintains automatic backups under <code class="language-plaintext highlighter-rouge">/etc/lvm/backup</code>. They’re in their original form, are text-based (so easily readable), and are ready for use with <code class="language-plaintext highlighter-rouge">vgcfgrestore</code>.</p>
	<p>Indeed, the recommended solution is to create a new, larger VG and migrate your data ASAP. After all, data security matters the most.</p>
	]]></content><author><name>iBug</name></author><category term="linux" /><category term="server" /><summary type="html"><![CDATA[An LVM volume group (VG) on our Proxmox VE cluster has failed to create new logical volumes, reporting that its metadata was full. At first this appears to be easy, “fine I’ll just add more space for metadata”, but it quickly revealed to be an versity to struggle through.]]></summary></entry></feed>